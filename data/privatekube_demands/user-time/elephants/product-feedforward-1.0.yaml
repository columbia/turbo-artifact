accuracy: 0.6259958865050983
adaptive_batch_size: 1
alphas:
- 1.5
- 1.75
- 2
- 2.5
- 3
- 4
- 5
- 6
- 8
- 16
- 32
- 64
batch_size: 295
best_alpha: 32.0
delta: 1.0e-09
device: cuda
dp: 1
dp_eval: 0
dropout: 0.25
dynamic_clipping: 0
embedding_dim: 100
epsilon: 0.9965800547893189
hidden_dim: 100
hidden_dim_1: 185
hidden_dim_2: 150
learning_rate: 0.01
learning_rate_scheduler: 1
loss: 1.5066938041744375
max_grad_norm: 1.0
max_text_len: 60
model: feedforward
n_blocks: 500
n_blocks_test: 200
n_epochs: 15
n_train_users: 87174
n_trainable_parameters: 48246
n_workers: 6
noise: 1.7494845581054685
non_dp_batch_size: 256
per_layer_clipping: 0
rdp_epsilons:
- 0.014675123262328787
- 0.01712725677123217
- 0.01958119229988843
- 0.024494481056080986
- 0.02941501321779146
- 0.03927790301649032
- 0.04917005367896065
- 0.059091659399621334
- 0.07902402408779689
- 0.15997213094198084
- 0.3280876084362088
- 20691.98700940067
target_epsilon: 1.0
task: product
test_size: 39077
timeframe_days: 1
total_time: 52.13570547103882
train_size: 165215
training_accuracy_epochs:
- 0.5761677605620885
- 0.6463085243257426
- 0.6560298679238659
- 0.6635334606898033
- 0.6670956551018408
- 0.6691295524774972
- 0.6753806318266917
- 0.6791956261052924
- 0.6815972354452489
- 0.6834242950051518
- 0.6849525934558803
- 0.6854237212973125
- 0.6860787070403664
- 0.6862625629214917
- 0.6874001664630437
training_loss_epochs:
- 1.4885519783375627
- 1.2928450410648928
- 1.322340316691641
- 1.3437128353927095
- 1.389405806994034
- 1.405345007524652
- 1.364712762024443
- 1.3371743301213799
- 1.3177753315133565
- 1.2989263865907315
- 1.2874009158651707
- 1.281752889439211
- 1.2869599431248036
- 1.2817154284250938
- 1.2749572018445547
training_time: 25.331976652145386
user_level: 1
validation_accuracy_epochs:
- 0.5741504881117079
- 0.5944632675912646
- 0.5876262929704454
- 0.6025104297531976
- 0.6103004905912611
- 0.6044428043895298
- 0.6150773723920187
- 0.6178907672564189
- 0.6224465674824184
- 0.6260443713929918
- 0.6282207383049859
- 0.6280389653311835
- 0.6279325207074483
- 0.6273429857359992
- 0.6247015409999424
validation_loss_epochs:
- 1.5502708382076686
- 1.4841569582621257
- 1.678906226158142
- 1.5938374837239584
- 1.5285175376468234
- 1.7587112506230673
- 1.5613153298695883
- 1.5398182259665596
- 1.4953919755087959
- 1.486386357413398
- 1.4799356434080335
- 1.4778303623199462
- 1.4738546556896635
- 1.4838465293248495
- 1.49241144657135
virtual_batch_multiplier: 0
vocab_size: 10000
