accuracy: 0.8203089113595785
adaptive_batch_size: 1
alphas:
- 1.5
- 1.75
- 2
- 2.5
- 3
- 4
- 5
- 6
- 8
- 16
- 32
- 64
batch_size: 64
best_alpha: 64.0
delta: 1.0e-09
device: cuda
dp: 1
dp_eval: 0
dropout: 0.25
dynamic_clipping: 0
embedding_dim: 100
epsilon: 0.4975956409232192
hidden_dim: 100
hidden_dim_1: 240
hidden_dim_2: 195
learning_rate: 0.0005
learning_rate_scheduler: 1
loss: 0.6937417978019577
max_grad_norm: 1.0
max_text_len: 140
model: bert
n_blocks: 1000
n_blocks_test: 200
n_epochs: 3
n_train_users: 162745
n_trainable_parameters: 855809
n_workers: 6
noise: 2.2977225983142846
non_dp_batch_size: 256
per_layer_clipping: 0
rdp_epsilons:
- 0.001107299773707382
- 0.0012920191431931016
- 0.0014767869945098012
- 0.0018464682141531596
- 0.002216343658358833
- 0.002956678067730746
- 0.0036977919563479867
- 0.004439687064293411
- 0.005925827930680611
- 0.01190199265836721
- 0.024009024934092685
- 0.16865491335264124
target_epsilon: 0.5
task: sentiment
test_size: 39786
timeframe_days: 1
total_time: 788.4687283039093
train_size: 298746
training_accuracy_epochs:
- 0.6450936762391818
- 0.6940216856805664
- 0.7668297600314713
training_loss_epochs:
- 1.074548800602661
- 0.8912378339365089
- 0.8024064480883225
training_time: 755.3892636299133
user_level: 1
validation_accuracy_epochs:
- 0.6600596669774789
- 0.7631567653555137
- 0.8180052371552358
validation_loss_epochs:
- 0.9749184204981878
- 0.7456462184110513
- 0.6975930219945999
virtual_batch_multiplier: 6
vocab_size: 10000
