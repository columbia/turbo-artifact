accuracy: 0.7169310060658849
adaptive_batch_size: 1
alphas:
- 1.5
- 1.75
- 2
- 2.5
- 3
- 4
- 5
- 6
- 8
- 16
- 32
- 64
batch_size: 295
best_alpha: 64.0
delta: 1.0e-09
device: cuda
dp: 1
dp_eval: 0
dropout: 0.25
dynamic_clipping: 0
embedding_dim: 100
epsilon: 0.4974676310206343
hidden_dim: 100
hidden_dim_1: 240
hidden_dim_2: 195
learning_rate: 0.01
learning_rate_scheduler: 1
loss: 0.5698354123230267
max_grad_norm: 1.0
max_text_len: 50
model: bow
n_blocks: 500
n_blocks_test: 200
n_epochs: 15
n_train_users: 87174
n_trainable_parameters: 101
n_workers: 6
noise: 3.214313659667969
non_dp_batch_size: 256
per_layer_clipping: 0
rdp_epsilons:
- 0.003861693504170205
- 0.004505708054836077
- 0.0051498365762135834
- 0.006438436124562311
- 0.007727492485084684
- 0.010306977019999792
- 0.012888292847546253
- 0.015471442640644584
- 0.020643254846442704
- 0.04140440121467214
- 0.08328596661352614
- 0.16852690345005633
target_epsilon: 0.5
task: sentiment
test_size: 39077
timeframe_days: 1
total_time: 43.504236936569214
train_size: 165215
training_accuracy_epochs:
- 0.6388049335803015
- 0.64034471976555
- 0.6481126013448683
- 0.666038488129438
- 0.677874167894913
- 0.6851479392940715
- 0.6891812625577894
- 0.693249059127549
- 0.6960873248213428
- 0.6978339494284936
- 0.7024303300906036
- 0.7021200749833705
- 0.7034645149263284
- 0.7048204482611963
- 0.7042803709789858
training_loss_epochs:
- 0.680235392360364
- 0.6442362185251915
- 0.6258369494292696
- 0.6087409185150923
- 0.601070471133216
- 0.5977561881986715
- 0.594077687142259
- 0.5905003976013701
- 0.5875379830093707
- 0.5860485634561312
- 0.5836964645628202
- 0.5846592376797887
- 0.5824755131188085
- 0.581529535883564
- 0.5828739494590436
training_time: 17.616421461105347
user_level: 1
validation_accuracy_epochs:
- 0.6522148436970181
- 0.6593498640590244
- 0.6731433629989624
- 0.6865569419331021
- 0.6935756908522712
- 0.6957422335942586
- 0.7015917393896315
- 0.6987865289052327
- 0.7024956928359137
- 0.7040022889773051
- 0.7028281251589458
- 0.7082960685094197
- 0.7090362668037414
- 0.7092884553803338
- 0.7109768178727892
validation_loss_epochs:
- 0.6421496232350667
- 0.6204601658715142
- 0.6036726011170281
- 0.5941350883907742
- 0.5848050687048171
- 0.5842515428860983
- 0.5809330887264675
- 0.5868860946761237
- 0.5835507492224375
- 0.5834000733163621
- 0.5872172726525201
- 0.5746545447243585
- 0.5821361819903056
- 0.5781240304311116
- 0.5775788797272576
virtual_batch_multiplier: 0
vocab_size: 10000
