accuracy: 0.6049874244479958
adaptive_batch_size: 1
alphas:
- 1.5
- 1.75
- 2
- 2.5
- 3
- 4
- 5
- 6
- 8
- 16
- 32
- 64
batch_size: 180
best_alpha: 6.0
delta: 1.0e-09
device: cuda
dp: 1
dp_eval: 0
dropout: 0.25
dynamic_clipping: 0
embedding_dim: 100
epsilon: 4.961422942925866
hidden_dim: 40
hidden_dim_1: 240
hidden_dim_2: 195
learning_rate: 0.01
learning_rate_scheduler: 1
loss: 1.422562422555521
max_grad_norm: 1.0
max_text_len: 30
model: lstm
n_blocks: 200
n_blocks_test: 200
n_epochs: 15
n_train_users: 32690
n_trainable_parameters: 23171
n_workers: 6
noise: 0.8644836425781249
non_dp_batch_size: 256
per_layer_clipping: 0
rdp_epsilons:
- 0.171227496560147
- 0.2011191998056999
- 0.23144412379131044
- 0.29348214685473034
- 0.35754699867989004
- 0.49292598058379217
- 0.6415109507291522
- 0.8167697755365846
- 8.18287157867774
- 13998.781685649157
- 43548.12519441418
- 101906.31117998634
target_epsilon: 5.0
task: product
test_size: 39077
timeframe_days: 1
total_time: 139.68866086006165
train_size: 64934
training_accuracy_epochs:
- 0.4990792050340228
- 0.5818293613294212
- 0.6110804336176393
- 0.6213628149164315
- 0.6265193523623008
- 0.6299263489180507
- 0.6305402224235113
- 0.6381522552084528
- 0.6381522558670676
- 0.6430325498238453
- 0.6457949787872272
- 0.6506138868753423
- 0.6492633658219438
- 0.6520257961025554
- 0.6561694425113952
training_loss_epochs:
- 1.7720862679718608
- 1.5347001269377398
- 1.4804638828361891
- 1.4458317137554864
- 1.4358320993613143
- 1.4008620305614576
- 1.4018394788984436
- 1.3750549758995436
- 1.362864421217481
- 1.3551694405013026
- 1.353123277919727
- 1.3379393269343929
- 1.3251695204834912
- 1.3186862320531139
- 1.3068460799053887
training_time: 114.42187070846558
user_level: 1
validation_accuracy_epochs:
- 0.515615066436872
- 0.5475162765751146
- 0.5726442692214495
- 0.5776255886032157
- 0.5806420527092399
- 0.5820949371546915
- 0.5818112843657193
- 0.5798256691188028
- 0.5782413315283109
- 0.5896430195194401
- 0.5783520283764356
- 0.595447644795457
- 0.5907153895456497
- 0.595641358257973
- 0.6016189480481082
validation_loss_epochs:
- 1.6959133752404827
- 1.635525203730962
- 1.5857301280923086
- 1.6116869792546311
- 1.627324834261855
- 1.6078157669877353
- 1.534359187295992
- 1.4904703555041796
- 1.5640694213240114
- 1.5416020024312687
- 1.5555044951504224
- 1.5841444959379223
- 1.5163386325313621
- 1.4854006946903386
- 1.4220541242050797
virtual_batch_multiplier: 0
vocab_size: 10000
