accuracy: 0.7222597446656764
adaptive_batch_size: 1
alphas:
- 1.5
- 1.75
- 2
- 2.5
- 3
- 4
- 5
- 6
- 8
- 16
- 32
- 64
batch_size: 295
best_alpha: 64.0
delta: 1.0e-09
device: cuda
dp: 1
dp_eval: 0
dropout: 0.25
dynamic_clipping: 0
embedding_dim: 100
epsilon: 0.4974676310206343
hidden_dim: 100
hidden_dim_1: 150
hidden_dim_2: 110
learning_rate: 0.01
learning_rate_scheduler: 1
loss: 1.0215240622821606
max_grad_norm: 1.0
max_text_len: 30
model: feedforward
n_blocks: 500
n_blocks_test: 200
n_epochs: 15
n_train_users: 87174
n_trainable_parameters: 31871
n_workers: 6
noise: 3.214313659667969
non_dp_batch_size: 256
per_layer_clipping: 0
rdp_epsilons:
- 0.003861693504170205
- 0.004505708054836077
- 0.0051498365762135834
- 0.006438436124562311
- 0.007727492485084684
- 0.010306977019999792
- 0.012888292847546253
- 0.015471442640644584
- 0.020643254846442704
- 0.04140440121467214
- 0.08328596661352614
- 0.16852690345005633
target_epsilon: 0.5
task: sentiment
test_size: 39077
timeframe_days: 1
total_time: 49.67663264274597
train_size: 165215
training_accuracy_epochs:
- 0.6398735907118199
- 0.6541223701784167
- 0.6902154455750675
- 0.6990864624411373
- 0.7026256753226457
- 0.7021200739731223
- 0.7055328858100762
- 0.7068313641063237
- 0.7082907141265222
- 0.7076472181384846
- 0.7075897673429069
- 0.7082217679185382
- 0.7078655499522969
- 0.7077736205973868
- 0.7070381988913326
training_loss_epochs:
- 0.9248346074152801
- 0.9985658336493929
- 0.9906400676500999
- 1.0415583695395518
- 1.065907428830357
- 1.072537399348566
- 1.0597378904536618
- 1.062222306809183
- 1.0504527473853806
- 1.0492988707655566
- 1.054619000725827
- 1.0526466224153164
- 1.050774133205414
- 1.052633182881242
- 1.052148368399022
training_time: 25.27207636833191
user_level: 1
validation_accuracy_epochs:
- 0.6580250435405307
- 0.7069712532891168
- 0.7121067643165588
- 0.7172029733657836
- 0.6990485456254747
- 0.713254717985789
- 0.7174911909633213
- 0.716852527194553
- 0.7181200292375353
- 0.7161876612239414
- 0.7181822564866808
- 0.7176680498652988
- 0.7176991661389669
- 0.7175927228397794
- 0.7167771975199382
validation_loss_epochs:
- 0.9147567172845205
- 0.7491221825281779
- 0.9130654017130534
- 0.9826917065514459
- 1.3029159016079372
- 1.0268983933660718
- 1.022910229365031
- 1.006557199690077
- 0.9995345658726162
- 1.0258794930246142
- 1.0127379020055136
- 1.0159505274560716
- 1.0202941139539083
- 1.017076732052697
- 1.0311874482366774
virtual_batch_multiplier: 0
vocab_size: 10000
