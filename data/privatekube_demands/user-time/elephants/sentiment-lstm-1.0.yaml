accuracy: 0.7680234779092602
adaptive_batch_size: 1
alphas:
- 1.5
- 1.75
- 2
- 2.5
- 3
- 4
- 5
- 6
- 8
- 16
- 32
- 64
batch_size: 295
best_alpha: 32.0
delta: 1.0e-09
device: cuda
dp: 1
dp_eval: 0
dropout: 0.25
dynamic_clipping: 0
embedding_dim: 100
epsilon: 0.9965800547893189
hidden_dim: 40
hidden_dim_1: 240
hidden_dim_2: 195
learning_rate: 0.01
learning_rate_scheduler: 1
loss: 0.6544149163970374
max_grad_norm: 1.0
max_text_len: 50
model: lstm
n_blocks: 500
n_blocks_test: 200
n_epochs: 15
n_train_users: 87174
n_trainable_parameters: 22761
n_workers: 6
noise: 1.7494845581054685
non_dp_batch_size: 256
per_layer_clipping: 0
rdp_epsilons:
- 0.014675123262328787
- 0.01712725677123217
- 0.01958119229988843
- 0.024494481056080986
- 0.02941501321779146
- 0.03927790301649032
- 0.04917005367896065
- 0.059091659399621334
- 0.07902402408779689
- 0.15997213094198084
- 0.3280876084362088
- 20691.98700940067
target_epsilon: 1.0
task: sentiment
test_size: 39077
timeframe_days: 1
total_time: 297.05728340148926
train_size: 165215
training_accuracy_epochs:
- 0.638023548510115
- 0.641953452966981
- 0.7097500655610682
- 0.7293766078302416
- 0.7329043271177906
- 0.7401436284437017
- 0.7438552050267235
- 0.745337539406146
- 0.747290999808554
- 0.7494512984308146
- 0.750795740394269
- 0.7514277413739996
- 0.7515656317694712
- 0.7516345779774553
- 0.7517839617648368
training_loss_epochs:
- 0.6953140980106289
- 0.7470555966183291
- 0.7528671103008723
- 0.7232146273225041
- 0.7054071055630506
- 0.688851566435927
- 0.6946783417362278
- 0.696200263298164
- 0.6990250225794518
- 0.698782975390806
- 0.7038303763179455
- 0.7002546929706961
- 0.6988185973490699
- 0.697535371477321
- 0.6985892491825556
training_time: 270.934472322464
user_level: 1
validation_accuracy_epochs:
- 0.6533628026644389
- 0.6876426683531867
- 0.720330786705017
- 0.7487922655211554
- 0.7497093134456211
- 0.7578105211257935
- 0.7554654836654663
- 0.7585277875264486
- 0.7589748554759556
- 0.7622500538825989
- 0.761447627014584
- 0.7625202536582947
- 0.762006049686008
- 0.7615229619873894
- 0.7609645393159654
validation_loss_epochs:
- 0.6893021861712137
- 0.7617453389697605
- 0.7639069371753269
- 0.663918383916219
- 0.638920373386807
- 0.6467061089144812
- 0.6660519070095486
- 0.6587298976050483
- 0.6593847089343601
- 0.6701721337106493
- 0.667571222782135
- 0.6642314778433905
- 0.6653987871276008
- 0.6678984920183818
- 0.667643067571852
virtual_batch_multiplier: 0
vocab_size: 10000
