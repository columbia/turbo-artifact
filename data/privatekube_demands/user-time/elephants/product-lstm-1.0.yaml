accuracy: 0.6057530856670293
adaptive_batch_size: 1
alphas:
- 1.5
- 1.75
- 2
- 2.5
- 3
- 4
- 5
- 6
- 8
- 16
- 32
- 64
batch_size: 295
best_alpha: 32.0
delta: 1.0e-09
device: cuda
dp: 1
dp_eval: 0
dropout: 0.25
dynamic_clipping: 0
embedding_dim: 100
epsilon: 0.9965800547893189
hidden_dim: 40
hidden_dim_1: 240
hidden_dim_2: 195
learning_rate: 0.01
learning_rate_scheduler: 1
loss: 1.4820528881890433
max_grad_norm: 1.0
max_text_len: 30
model: lstm
n_blocks: 500
n_blocks_test: 200
n_epochs: 15
n_train_users: 87174
n_trainable_parameters: 23171
n_workers: 6
noise: 1.7494845581054685
non_dp_batch_size: 256
per_layer_clipping: 0
rdp_epsilons:
- 0.014675123262328787
- 0.01712725677123217
- 0.01958119229988843
- 0.024494481056080986
- 0.02941501321779146
- 0.03927790301649032
- 0.04917005367896065
- 0.059091659399621334
- 0.07902402408779689
- 0.15997213094198084
- 0.3280876084362088
- 20691.98700940067
target_epsilon: 1.0
task: product
test_size: 39077
timeframe_days: 1
total_time: 201.28178715705872
train_size: 165215
training_accuracy_epochs:
- 0.53239873080688
- 0.593737424228151
- 0.609916681152279
- 0.6213961419412646
- 0.6279000181262776
- 0.6312898488368018
- 0.6347141532574669
- 0.635794302770647
- 0.6371732170298948
- 0.6404941017344846
- 0.6419879264750723
- 0.6484688225439039
- 0.6531226564261873
- 0.6533869502908093
- 0.6552255022323737
training_loss_epochs:
- 1.7050939741781201
- 1.5135395914821301
- 1.4600787857831534
- 1.440384333416567
- 1.430008249767756
- 1.407270730956126
- 1.400143450397556
- 1.3876457392159154
- 1.3763286639068086
- 1.3617168802326007
- 1.3632320206044084
- 1.3344681574126422
- 1.3177300738076032
- 1.3046323392350796
- 1.3066099063824799
training_time: 175.2124481201172
user_level: 1
validation_accuracy_epochs:
- 0.5328878998756409
- 0.5460132559140524
- 0.5619831283887228
- 0.5649078792995876
- 0.5714304394192166
- 0.5794284674856398
- 0.5801686671045091
- 0.5728485955132379
- 0.5882027294900682
- 0.5844935682084825
- 0.5892966389656067
- 0.5977826820479499
- 0.6059231890572442
- 0.5985228776931762
- 0.6077441970507304
validation_loss_epochs:
- 1.7345781538221572
- 1.6650224659177992
- 1.6051148308648004
- 1.5644431034723918
- 1.5554937415652805
- 1.6407421747843425
- 1.5898392809761894
- 1.5206192758348254
- 1.5529202540715537
- 1.4751241948869493
- 1.5043811798095703
- 1.4942549864451091
- 1.4578572829564413
- 1.472242365943061
- 1.4674058808220758
virtual_batch_multiplier: 0
vocab_size: 10000
