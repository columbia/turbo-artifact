accuracy: 0.8018471777887273
adaptive_batch_size: 1
alphas:
- 1.5
- 1.75
- 2
- 2.5
- 3
- 4
- 5
- 6
- 8
- 16
- 32
- 64
batch_size: 295
best_alpha: 6.0
delta: 1.0e-09
device: cuda
dp: 1
dp_eval: 0
dropout: 0.25
dynamic_clipping: 0
embedding_dim: 100
epsilon: 4.990773805662074
hidden_dim: 40
hidden_dim_1: 240
hidden_dim_2: 195
learning_rate: 0.01
learning_rate_scheduler: 1
loss: 0.5938225706717125
max_grad_norm: 1.0
max_text_len: 50
model: lstm
n_blocks: 500
n_blocks_test: 200
n_epochs: 15
n_train_users: 87174
n_trainable_parameters: 22761
n_workers: 6
noise: 0.7805611419677734
non_dp_batch_size: 256
per_layer_clipping: 0
rdp_epsilons:
- 0.1558258180159023
- 0.18313805928304214
- 0.2108911669736089
- 0.2678380404103581
- 0.3269562627693356
- 0.453643609991126
- 0.6001477928894902
- 0.846120638272792
- 605.2461690235
- 31251.177848935728
- 90219.10209556056
- 206835.10557605675
target_epsilon: 5.0
task: sentiment
test_size: 39077
timeframe_days: 1
total_time: 287.68823623657227
train_size: 165215
training_accuracy_epochs:
- 0.6456765197091183
- 0.7004423957760051
- 0.7365584508847383
- 0.756874452809156
- 0.7652053915848166
- 0.771674797898632
- 0.7756047008401257
- 0.7769836163116713
- 0.7767652895491002
- 0.7794311887126858
- 0.7828899634086479
- 0.7846825524912042
- 0.7870496887271687
- 0.7876012531377501
- 0.7881757994829598
training_loss_epochs:
- 0.7014778365523128
- 0.7235920572684983
- 0.6980626758882555
- 0.6690636087272127
- 0.6676860486046743
- 0.6531159829285185
- 0.648519396983971
- 0.6472689058821081
- 0.6498301175691313
- 0.6422364945128812
- 0.6309695163015592
- 0.6315092125181424
- 0.6242481354939735
- 0.6227802589788275
- 0.6192093633999258
training_time: 261.9363193511963
user_level: 1
validation_accuracy_epochs:
- 0.6989502933290269
- 0.7312535776032342
- 0.7708065032958984
- 0.7727159447140164
- 0.7851944539282057
- 0.7860853128963047
- 0.7846229328049554
- 0.7896208816104465
- 0.7893244783083598
- 0.7963252173529731
- 0.7913894957966274
- 0.8004421419567532
- 0.7978809396425883
- 0.7961483611000909
- 0.7967690070470174
validation_loss_epochs:
- 0.710571198993259
- 0.6937116795116001
- 0.652633649110794
- 0.6691186454561021
- 0.6426471047931247
- 0.6078028857707978
- 0.6527694450484381
- 0.6206060647964478
- 0.672059628698561
- 0.5772299336062537
- 0.6689264469676548
- 0.5846268322732714
- 0.5838208463456895
- 0.6021145721276601
- 0.6035183886686961
virtual_batch_multiplier: 0
vocab_size: 10000
