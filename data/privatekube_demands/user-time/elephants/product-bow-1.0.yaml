accuracy: 0.6004046286855426
adaptive_batch_size: 1
alphas:
- 1.5
- 1.75
- 2
- 2.5
- 3
- 4
- 5
- 6
- 8
- 16
- 32
- 64
batch_size: 295
best_alpha: 32.0
delta: 1.0e-09
device: cuda
dp: 1
dp_eval: 0
dropout: 0.25
dynamic_clipping: 0
embedding_dim: 100
epsilon: 0.9965800547893189
hidden_dim: 100
hidden_dim_1: 240
hidden_dim_2: 195
learning_rate: 0.01
learning_rate_scheduler: 1
loss: 1.271336785832742
max_grad_norm: 1.0
max_text_len: 75
model: bow
n_blocks: 500
n_blocks_test: 200
n_epochs: 15
n_train_users: 87174
n_trainable_parameters: 1111
n_workers: 6
noise: 1.7494845581054685
non_dp_batch_size: 256
per_layer_clipping: 0
rdp_epsilons:
- 0.014675123262328787
- 0.01712725677123217
- 0.01958119229988843
- 0.024494481056080986
- 0.02941501321779146
- 0.03927790301649032
- 0.04917005367896065
- 0.059091659399621334
- 0.07902402408779689
- 0.15997213094198084
- 0.3280876084362088
- 20691.98700940067
target_epsilon: 1.0
task: product
test_size: 39077
timeframe_days: 1
total_time: 43.36032962799072
train_size: 165215
training_accuracy_epochs:
- 0.4944211380808788
- 0.5940706602597641
- 0.6179373652248059
- 0.6295662075786267
- 0.6357253585831594
- 0.6420453811095933
- 0.6456535393908872
- 0.6495374804836208
- 0.6533065131155111
- 0.6554438279846967
- 0.6575236928665031
- 0.6587991876117254
- 0.6609479950646223
- 0.6619706899432812
- 0.66193621643519
training_loss_epochs:
- 1.6189926935454546
- 1.364744114471694
- 1.28619930824991
- 1.2372238244040539
- 1.2057114364737171
- 1.186567027083898
- 1.1648643346156105
- 1.1495360233015934
- 1.1327747118675102
- 1.1233277306718341
- 1.1113906296633058
- 1.1029086898949187
- 1.093789822772398
- 1.08375105352725
- 1.0780826314020966
training_time: 18.229199409484863
user_level: 1
validation_accuracy_epochs:
- 0.5199230293432872
- 0.5500679539309608
- 0.5633963770336575
- 0.5726357089148627
- 0.5792958272827996
- 0.5828723377651639
- 0.5829116437170241
- 0.5893588701883952
- 0.5913927714029948
- 0.5949774728880988
- 0.6009203248553806
- 0.5988815135425991
- 0.6031802097956339
- 0.5985670990414089
- 0.6019569251272413
validation_loss_epochs:
- 1.6150084416071573
- 1.5198298189375135
- 1.4485845565795898
- 1.4082280503378974
- 1.3815178977118598
- 1.364437625143263
- 1.3437900967068142
- 1.3330676211251153
- 1.3204112423790826
- 1.3100216229756674
- 1.285966740714179
- 1.2797239144643149
- 1.2670671661694846
- 1.2571162064870198
- 1.2560340801874796
virtual_batch_multiplier: 0
vocab_size: 10000
