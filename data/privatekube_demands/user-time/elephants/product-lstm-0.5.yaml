accuracy: 0.6348521073122282
adaptive_batch_size: 1
alphas:
- 1.5
- 1.75
- 2
- 2.5
- 3
- 4
- 5
- 6
- 8
- 16
- 32
- 64
batch_size: 530
best_alpha: 64.0
delta: 1.0e-09
device: cuda
dp: 1
dp_eval: 0
dropout: 0.25
dynamic_clipping: 0
embedding_dim: 100
epsilon: 0.4964451327763088
hidden_dim: 40
hidden_dim_1: 240
hidden_dim_2: 195
learning_rate: 0.01
learning_rate_scheduler: 1
loss: 1.3590690783552222
max_grad_norm: 1.0
max_text_len: 30
model: lstm
n_blocks: 2000
n_blocks_test: 200
n_epochs: 15
n_train_users: 281120
n_trainable_parameters: 23171
n_workers: 6
noise: 2.4513818359375
non_dp_batch_size: 256
per_layer_clipping: 0
rdp_epsilons:
- 0.0038364763653930822
- 0.0044762930585307
- 0.005116225316411823
- 0.006396436688438435
- 0.007677110759145354
- 0.010239848469507973
- 0.01280444126509522
- 0.015370891970450738
- 0.02050937844377405
- 0.04113821052507474
- 0.08276016012459009
- 0.16750440520573084
target_epsilon: 0.5
task: product
test_size: 39077
timeframe_days: 1
total_time: 336.81503081321716
train_size: 513239
training_accuracy_epochs:
- 0.6011214040079207
- 0.6589996536947647
- 0.6716910038354262
- 0.6735101552504413
- 0.680534008538948
- 0.6827340799682545
- 0.6879067382722531
- 0.6917942410370089
- 0.6979708186860355
- 0.7010893653023917
- 0.7042541933509538
- 0.7037735960393582
- 0.7060484260882971
- 0.7073335811776935
- 0.7099288109338509
training_loss_epochs:
- 1.5021891830102452
- 1.2999425579916757
- 1.2745729149512526
- 1.2603303913800221
- 1.2200502924199375
- 1.2103148588594401
- 1.1994577146926015
- 1.1829870786306993
- 1.1708946330367394
- 1.1611996261578685
- 1.1516096940580405
- 1.1360420732003338
- 1.1283274372793592
- 1.1302563235444842
- 1.1210734110958172
training_time: 305.4290153980255
user_level: 1
validation_accuracy_epochs:
- 0.5492613220214844
- 0.5792694568634034
- 0.590513265132904
- 0.596908130645752
- 0.5984915590286255
- 0.598755955696106
- 0.6178231692314148
- 0.6211439228057861
- 0.6191357851028443
- 0.6226681566238403
- 0.6237193298339844
- 0.6291843771934509
- 0.6269202208518982
- 0.6279876780509949
- 0.6351491022109985
validation_loss_epochs:
- 1.663168716430664
- 1.489135971069336
- 1.5972382068634032
- 1.5286023664474486
- 1.5065508937835694
- 1.5167416191101075
- 1.4256094408035278
- 1.390147523880005
- 1.4039186286926268
- 1.3989363241195678
- 1.373102912902832
- 1.3847069835662842
- 1.392529377937317
- 1.3876255655288696
- 1.3747350454330445
virtual_batch_multiplier: 0
vocab_size: 10000
