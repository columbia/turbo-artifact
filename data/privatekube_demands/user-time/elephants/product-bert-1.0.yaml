accuracy: 0.7044492133943981
adaptive_batch_size: 1
alphas:
- 1.5
- 1.75
- 2
- 2.5
- 3
- 4
- 5
- 6
- 8
- 16
- 32
- 64
batch_size: 64
best_alpha: 32.0
delta: 1.0e-09
device: cuda
dp: 1
dp_eval: 0
dropout: 0.25
dynamic_clipping: 0
embedding_dim: 100
epsilon: 0.9989633776131703
hidden_dim: 100
hidden_dim_1: 240
hidden_dim_2: 195
learning_rate: 0.0005
learning_rate_scheduler: 1
loss: 1.1168990277017428
max_grad_norm: 1.0
max_text_len: 140
model: bert
n_blocks: 2000
n_blocks_test: 200
n_epochs: 3
n_train_users: 283173
n_trainable_parameters: 858379
n_workers: 6
noise: 1.5875999617576597
non_dp_batch_size: 256
per_layer_clipping: 0
rdp_epsilons:
- 0.0019798761490648076
- 0.00231044428554128
- 0.002641181156893022
- 0.00330316192576705
- 0.00396582005245154
- 0.005293174731355094
- 0.00662325800654646
- 0.007956082799878654
- 0.010630009181801509
- 0.02143803798265258
- 0.3304709312600604
- 10419.00432987415
target_epsilon: 1.0
task: product
test_size: 39786
timeframe_days: 1
total_time: 1344.7978658676147
train_size: 514963
training_accuracy_epochs:
- 0.6570729260849909
- 0.7445644495931284
- 0.7685034753616636
training_loss_epochs:
- 1.1892570762829366
- 0.8927790140008948
- 0.855960614410032
training_time: 1307.3086309432983
user_level: 1
validation_accuracy_epochs:
- 0.6432220124854491
- 0.6872961025398511
- 0.7078146464549578
validation_loss_epochs:
- 1.187252957946979
- 1.1293462772782032
- 1.1088179325541625
virtual_batch_multiplier: 8
vocab_size: 10000
