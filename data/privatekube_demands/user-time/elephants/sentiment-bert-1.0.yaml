accuracy: 0.8041288661995118
adaptive_batch_size: 1
alphas:
- 1.5
- 1.75
- 2
- 2.5
- 3
- 4
- 5
- 6
- 8
- 16
- 32
- 64
batch_size: 64
best_alpha: 32.0
delta: 1.0e-09
device: cuda
dp: 1
dp_eval: 0
dropout: 0.25
dynamic_clipping: 0
embedding_dim: 100
epsilon: 0.9931651762205516
hidden_dim: 100
hidden_dim_1: 240
hidden_dim_2: 195
learning_rate: 0.0005
learning_rate_scheduler: 1
loss: 0.6905383824751117
max_grad_norm: 1.0
max_text_len: 140
model: bert
n_blocks: 500
n_blocks_test: 200
n_epochs: 3
n_train_users: 88022
n_trainable_parameters: 855809
n_workers: 6
noise: 1.651257085800171
non_dp_batch_size: 256
per_layer_clipping: 0
rdp_epsilons:
- 0.0028984042221104948
- 0.0033827146244220785
- 0.0038673817541993016
- 0.004837788575059676
- 0.00580962944804642
- 0.0077576326029193746
- 0.0097114299730522
- 0.011671060776289481
- 0.015607981924447723
- 0.03159718540628883
- 0.3246727298674416
- 5988.848325861892
target_epsilon: 1.0
task: sentiment
test_size: 39786
timeframe_days: 1
total_time: 443.96335554122925
train_size: 166581
training_accuracy_epochs:
- 0.6425795454545454
- 0.6666477272727273
- 0.7448068181818182
training_loss_epochs:
- 1.0813277371146461
- 0.9558442948081277
- 0.7983497206297788
training_time: 413.3987579345703
user_level: 1
validation_accuracy_epochs:
- 0.659791380740129
- 0.7427669987082481
- 0.7986134961247444
validation_loss_epochs:
- 0.9949375663239223
- 0.7253859378397465
- 0.695630069105671
virtual_batch_multiplier: 4
vocab_size: 10000
