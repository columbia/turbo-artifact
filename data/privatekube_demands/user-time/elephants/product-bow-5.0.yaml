accuracy: 0.6175145188668617
adaptive_batch_size: 1
alphas:
- 1.5
- 1.75
- 2
- 2.5
- 3
- 4
- 5
- 6
- 8
- 16
- 32
- 64
batch_size: 295
best_alpha: 6.0
delta: 1.0e-09
device: cuda
dp: 1
dp_eval: 0
dropout: 0.25
dynamic_clipping: 0
embedding_dim: 100
epsilon: 4.990773805662074
hidden_dim: 100
hidden_dim_1: 240
hidden_dim_2: 195
learning_rate: 0.01
learning_rate_scheduler: 1
loss: 1.166724597601066
max_grad_norm: 1.0
max_text_len: 75
model: bow
n_blocks: 500
n_blocks_test: 200
n_epochs: 15
n_train_users: 87174
n_trainable_parameters: 1111
n_workers: 6
noise: 0.7805611419677734
non_dp_batch_size: 256
per_layer_clipping: 0
rdp_epsilons:
- 0.1558258180159023
- 0.18313805928304214
- 0.2108911669736089
- 0.2678380404103581
- 0.3269562627693356
- 0.453643609991126
- 0.6001477928894902
- 0.846120638272792
- 605.2461690235
- 31251.177848935728
- 90219.10209556056
- 206835.10557605675
target_epsilon: 5.0
task: product
test_size: 39077
timeframe_days: 1
total_time: 43.74915146827698
train_size: 165215
training_accuracy_epochs:
- 0.5136225169745542
- 0.612502145767212
- 0.6356449212058116
- 0.6461706315056752
- 0.6534903689966364
- 0.6578684214818276
- 0.6612352676310782
- 0.6646595748804384
- 0.6679115111544981
- 0.6699454095404027
- 0.6727606932995683
- 0.6736225130194324
- 0.6749554648237713
- 0.6776098750405393
- 0.6789543145793979
training_loss_epochs:
- 1.566403308965392
- 1.2922049534522881
- 1.2071446016683416
- 1.156640249389713
- 1.1234614046953493
- 1.0973517872519412
- 1.0782690553341883
- 1.060811672372333
- 1.045309824660673
- 1.0314298255968901
- 1.0189800492787766
- 1.0130102064649937
- 1.0050803778535229
- 0.9970582990323082
- 0.9884349083496352
training_time: 18.073591232299805
user_level: 1
validation_accuracy_epochs:
- 0.5352542267905341
- 0.5582166459825304
- 0.5870678689744737
- 0.59048390256034
- 0.5919511927498712
- 0.599767451816135
- 0.5994268337885539
- 0.6062376062075298
- 0.6026168730523851
- 0.610619827111562
- 0.6108589159117804
- 0.6120953030056424
- 0.6122901770803664
- 0.61816096968121
- 0.6180463327301873
validation_loss_epochs:
- 1.5615307304594253
- 1.46849258740743
- 1.3654874563217163
- 1.331995431582133
- 1.2912978251775107
- 1.2677227285173205
- 1.254887745115492
- 1.2272889375686646
- 1.2257308138741387
- 1.1893728772799175
- 1.184748355547587
- 1.17849903371599
- 1.1738920582665338
- 1.1553821616702609
- 1.1531500816345215
virtual_batch_multiplier: 0
vocab_size: 10000
