accuracy: 0.7031045916977279
adaptive_batch_size: 1
alphas:
- 1.5
- 1.75
- 2
- 2.5
- 3
- 4
- 5
- 6
- 8
- 16
- 32
- 64
batch_size: 180
best_alpha: 32.0
delta: 1.0e-09
device: cuda
dp: 1
dp_eval: 0
dropout: 0.25
dynamic_clipping: 0
embedding_dim: 100
epsilon: 0.9916521164203631
hidden_dim: 100
hidden_dim_1: 150
hidden_dim_2: 110
learning_rate: 0.01
learning_rate_scheduler: 1
loss: 0.9520852974522005
max_grad_norm: 1.0
max_text_len: 30
model: feedforward
n_blocks: 200
n_blocks_test: 200
n_epochs: 15
n_train_users: 32690
n_trainable_parameters: 31871
n_workers: 6
noise: 2.1767263793945313
non_dp_batch_size: 256
per_layer_clipping: 0
rdp_epsilons:
- 0.014496788899859392
- 0.016918773257299152
- 0.019342436425286075
- 0.024194809166289133
- 0.029053926970663335
- 0.03879247787862552
- 0.04855825021473061
- 0.058351406639679346
- 0.07802053051498409
- 0.1578260696927979
- 0.3231596700672531
- 3989.910512384025
target_epsilon: 1.0
task: sentiment
test_size: 39077
timeframe_days: 1
total_time: 40.93640208244324
train_size: 64934
training_accuracy_epochs:
- 0.635144274867042
- 0.6378760127072834
- 0.6535297869318757
- 0.6701350683006793
- 0.6792510879632517
- 0.6844690142415505
- 0.682627394054476
- 0.6856660661776421
- 0.6861264712244107
- 0.6868938135178708
- 0.6849601137045339
- 0.6860343919274556
- 0.6867710394753935
- 0.6862185538144402
- 0.6856660681534867
training_loss_epochs:
- 0.8690073914949407
- 0.9927134951833863
- 0.9837569054319055
- 0.9885167071173863
- 0.9973331212338822
- 1.0022132307784992
- 0.9946881061759443
- 0.9930300218624305
- 0.986478091932792
- 0.996107816696167
- 0.9908152917472038
- 0.9941891115673339
- 0.9856472104293865
- 0.9818252502883995
- 0.9923655170103463
training_time: 18.03192162513733
user_level: 1
validation_accuracy_epochs:
- 0.6540265777339674
- 0.6579355295390299
- 0.6901895812112991
- 0.6859070315752944
- 0.6856994751381548
- 0.6994672923871915
- 0.6978760369836468
- 0.700740294097221
- 0.701653536868422
- 0.7008648326952164
- 0.7028435150237933
- 0.703051070644431
- 0.7023938183915125
- 0.7016051125853029
- 0.7019026067158948
validation_loss_epochs:
- 0.8595877787838243
- 0.9930558400611355
- 0.7841257795895615
- 1.0396725813003436
- 1.1831192031298599
- 0.9642601119328852
- 1.0082452542161289
- 0.9690962246019547
- 0.9788901397626694
- 0.964221571406273
- 0.9550913400845985
- 0.9546898464633994
- 0.954859972816624
- 0.9628071107276498
- 0.9632460205522302
virtual_batch_multiplier: 0
vocab_size: 10000
