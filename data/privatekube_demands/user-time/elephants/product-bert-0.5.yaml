accuracy: 0.7236676523731452
adaptive_batch_size: 1
alphas:
- 1.5
- 1.75
- 2
- 2.5
- 3
- 4
- 5
- 6
- 8
- 16
- 32
- 64
batch_size: 64
best_alpha: 64.0
delta: 1.0e-09
device: cuda
dp: 1
dp_eval: 0
dropout: 0.25
dynamic_clipping: 0
embedding_dim: 100
epsilon: 0.49753564125578587
hidden_dim: 100
hidden_dim_1: 240
hidden_dim_2: 195
learning_rate: 0.0005
learning_rate_scheduler: 1
loss: 1.0689587264869758
max_grad_norm: 1.0
max_text_len: 140
model: bert
n_blocks: 5000
n_blocks_test: 200
n_epochs: 3
n_train_users: 741310
n_trainable_parameters: 858379
n_workers: 6
noise: 2.1679645842313766
non_dp_batch_size: 256
per_layer_clipping: 0
rdp_epsilons:
- 0.000598632318883574
- 0.00069845443707095
- 0.0007982908545309203
- 0.0009980066457662019
- 0.0011977797387534635
- 0.0015974979687291664
- 0.0019974458258325946
- 0.002397623592032872
- 0.003198669982563171
- 0.00641210870492792
- 0.01288388127645223
- 0.16859491368520793
target_epsilon: 0.5
task: product
test_size: 39786
timeframe_days: 1
total_time: 3456.171475172043
train_size: 1348622
training_accuracy_epochs:
- 0.6947270009497496
- 0.7680317518563288
- 0.780775125194267
training_loss_epochs:
- 1.06000296693045
- 0.8640871810915145
- 0.8323979897421684
training_time: 3407.3197712898254
user_level: 1
validation_accuracy_epochs:
- 0.6856005323620943
- 0.7155520262626501
- 0.7246952268939751
validation_loss_epochs:
- 1.1305251508378065
- 1.078494192029421
- 1.0652550189540937
virtual_batch_multiplier: 13
vocab_size: 10000
