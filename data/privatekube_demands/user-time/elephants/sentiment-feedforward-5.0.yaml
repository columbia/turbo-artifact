accuracy: 0.7158255689548996
adaptive_batch_size: 1
alphas:
- 1.5
- 1.75
- 2
- 2.5
- 3
- 4
- 5
- 6
- 8
- 16
- 32
- 64
batch_size: 123
best_alpha: 8.0
delta: 1.0e-09
device: cuda
dp: 1
dp_eval: 0
dropout: 0.25
dynamic_clipping: 0
embedding_dim: 100
epsilon: 4.957786355230931
hidden_dim: 100
hidden_dim_1: 150
hidden_dim_2: 110
learning_rate: 0.01
learning_rate_scheduler: 1
loss: 0.8871750213065237
max_grad_norm: 1.0
max_text_len: 30
model: feedforward
n_blocks: 100
n_blocks_test: 200
n_epochs: 15
n_train_users: 15295
n_trainable_parameters: 31871
n_workers: 6
noise: 0.932193841934204
non_dp_batch_size: 256
per_layer_clipping: 0
rdp_epsilons:
- 0.19225333215490106
- 0.22582404216297652
- 0.25987932184010104
- 0.3295320048656581
- 0.40141175545268765
- 0.5529196392685788
- 0.7175536032909298
- 0.9027165967631535
- 1.99731980709573
- 7554.402081376442
- 24986.491015258234
- 59380.31770069096
target_epsilon: 5.0
task: sentiment
test_size: 39077
timeframe_days: 1
total_time: 38.27911591529846
train_size: 29727
training_accuracy_epochs:
- 0.629163364969915
- 0.6332284060697402
- 0.6514555259097007
- 0.6688302957242535
- 0.6835824554004977
- 0.6918436678186539
- 0.6959087069957487
- 0.6944662712274059
- 0.695843140444448
- 0.6997114881392448
- 0.6964332264277243
- 0.6975478356884371
- 0.6978756612347018
- 0.7001048763913493
- 0.6993180950803142
training_loss_epochs:
- 0.8106226310614617
- 0.9297537260478542
- 0.9304664870423656
- 0.9078782801666567
- 0.9456039359492641
- 0.9254947266271037
- 0.9256954108995776
- 0.9324123455632117
- 0.9437059245763286
- 0.9264280204811404
- 0.9260176828792018
- 0.931142050893076
- 0.9294637081123167
- 0.9114518180008857
- 0.9178311310468181
training_time: 14.880610942840576
user_level: 1
validation_accuracy_epochs:
- 0.6533977366843313
- 0.6568574776064675
- 0.69917867656024
- 0.70527934521999
- 0.7102378246919164
- 0.7141598288743001
- 0.709634597009083
- 0.7136498892082358
- 0.7158637907145158
- 0.7155901620972831
- 0.7151320391106155
- 0.7156150374772414
- 0.7142614058728488
- 0.7152232527732849
- 0.7151465505923865
validation_loss_epochs:
- 0.7443032922609797
- 0.9332257481116168
- 0.7230236221034572
- 0.7550687581863044
- 0.8380417109660383
- 0.8579629997037491
- 0.951731412478213
- 0.8486404334599117
- 0.8895611256923316
- 0.8878911621165726
- 0.8984057588397332
- 0.894893079996109
- 0.8737070015016591
- 0.8803007889468715
- 0.8846155185744448
virtual_batch_multiplier: 0
vocab_size: 10000
