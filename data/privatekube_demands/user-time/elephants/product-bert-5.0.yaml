accuracy: 0.7092580098622865
adaptive_batch_size: 1
alphas:
- 1.5
- 1.75
- 2
- 2.5
- 3
- 4
- 5
- 6
- 8
- 16
- 32
- 64
batch_size: 64
best_alpha: 6.0
delta: 1.0e-09
device: cuda
dp: 1
dp_eval: 0
dropout: 0.25
dynamic_clipping: 0
embedding_dim: 100
epsilon: 4.990666888234838
hidden_dim: 100
hidden_dim_1: 240
hidden_dim_2: 195
learning_rate: 0.0005
learning_rate_scheduler: 1
loss: 1.0959279050397719
max_grad_norm: 1.0
max_text_len: 140
model: bert
n_blocks: 1000
n_blocks_test: 200
n_epochs: 3
n_train_users: 162745
n_trainable_parameters: 858379
n_workers: 6
noise: 0.7042679595947265
non_dp_batch_size: 256
per_layer_clipping: 0
rdp_epsilons:
- 0.03388228586130233
- 0.039920832421581676
- 0.046096459543005716
- 0.05891791485653973
- 0.07250819146491727
- 0.10349390750705845
- 0.1540347726838772
- 0.846013720845556
- 1464.7692172539346
- 12308.717176048756
- 33089.88499082512
- 74248.77059004249
target_epsilon: 5.0
task: product
test_size: 39786
timeframe_days: 1
total_time: 788.3108525276184
train_size: 298746
training_accuracy_epochs:
- 0.6508347265932337
- 0.7382904701022817
- 0.756626180173092
training_loss_epochs:
- 1.1809445843041928
- 0.9473429416503426
- 0.9112792842084267
training_time: 754.5865352153778
user_level: 1
validation_accuracy_epochs:
- 0.655788547717608
- 0.6961066278700645
- 0.7119462570318809
validation_loss_epochs:
- 1.180591794447257
- 1.1131188405247836
- 1.0881170788779855
virtual_batch_multiplier: 6
vocab_size: 10000
