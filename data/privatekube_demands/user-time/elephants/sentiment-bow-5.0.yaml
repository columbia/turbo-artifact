accuracy: 0.7101394477880226
adaptive_batch_size: 1
alphas:
- 1.5
- 1.75
- 2
- 2.5
- 3
- 4
- 5
- 6
- 8
- 16
- 32
- 64
batch_size: 123
best_alpha: 8.0
delta: 1.0e-09
device: cuda
dp: 1
dp_eval: 0
dropout: 0.25
dynamic_clipping: 0
embedding_dim: 100
epsilon: 4.957786355230931
hidden_dim: 100
hidden_dim_1: 240
hidden_dim_2: 195
learning_rate: 0.01
learning_rate_scheduler: 1
loss: 0.5750963030933584
max_grad_norm: 1.0
max_text_len: 50
model: bow
n_blocks: 100
n_blocks_test: 200
n_epochs: 15
n_train_users: 15295
n_trainable_parameters: 101
n_workers: 6
noise: 0.932193841934204
non_dp_batch_size: 256
per_layer_clipping: 0
rdp_epsilons:
- 0.19225333215490106
- 0.22582404216297652
- 0.25987932184010104
- 0.3295320048656581
- 0.40141175545268765
- 0.5529196392685788
- 0.7175536032909298
- 0.9027165967631535
- 1.99731980709573
- 7554.402081376442
- 24986.491015258234
- 59380.31770069096
target_epsilon: 5.0
task: sentiment
test_size: 39077
timeframe_days: 1
total_time: 34.03568124771118
train_size: 29727
training_accuracy_epochs:
- 0.6257539766450082
- 0.6296878882473514
- 0.6304746712407758
- 0.6372278837427017
- 0.6461447477340698
- 0.6553894310228287
- 0.6629294253164723
- 0.6717151557245562
- 0.6750589830260123
- 0.6785995046938619
- 0.6816155002001794
- 0.6843692371922154
- 0.6884342763693102
- 0.6888932330954459
- 0.6913191455025827
training_loss_epochs:
- 0.7000892902574232
- 0.6734616977553214
- 0.6526984216705445
- 0.6413982534600843
- 0.6314754130378846
- 0.6211054844240989
- 0.6148597415416471
- 0.6100529581308365
- 0.6060230580549086
- 0.6053584160343293
- 0.6014144764311852
- 0.6001759906930308
- 0.5964096044340441
- 0.5983062477842453
- 0.5932844031241632
training_time: 11.623194456100464
user_level: 1
validation_accuracy_epochs:
- 0.6533148153772894
- 0.6535511320492007
- 0.6558624640950617
- 0.6623383372459771
- 0.674695149907526
- 0.6740214431060935
- 0.6819483750271347
- 0.691917155711156
- 0.694823424208839
- 0.7004120788484249
- 0.6991848906256118
- 0.6991268480723759
- 0.6987267749489479
- 0.7076466460272951
- 0.7032768827564312
validation_loss_epochs:
- 0.6696753395053575
- 0.6341096691365512
- 0.6255301135890888
- 0.6156956429751415
- 0.6022362253575955
- 0.6077835509237254
- 0.601338155427069
- 0.591899073911163
- 0.5909224917303841
- 0.5809934645328881
- 0.5866918206777213
- 0.5884684869703257
- 0.5863862844570628
- 0.5752447686105404
- 0.580254113899087
virtual_batch_multiplier: 0
vocab_size: 10000
