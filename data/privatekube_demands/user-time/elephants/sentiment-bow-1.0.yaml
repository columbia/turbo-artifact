accuracy: 0.7042573780641643
adaptive_batch_size: 1
alphas:
- 1.5
- 1.75
- 2
- 2.5
- 3
- 4
- 5
- 6
- 8
- 16
- 32
- 64
batch_size: 180
best_alpha: 32.0
delta: 1.0e-09
device: cuda
dp: 1
dp_eval: 0
dropout: 0.25
dynamic_clipping: 0
embedding_dim: 100
epsilon: 0.9916521164203631
hidden_dim: 100
hidden_dim_1: 240
hidden_dim_2: 195
learning_rate: 0.01
learning_rate_scheduler: 1
loss: 0.5810725753187039
max_grad_norm: 1.0
max_text_len: 50
model: bow
n_blocks: 200
n_blocks_test: 200
n_epochs: 15
n_train_users: 32690
n_trainable_parameters: 101
n_workers: 6
noise: 2.1767263793945313
non_dp_batch_size: 256
per_layer_clipping: 0
rdp_epsilons:
- 0.014496788899859392
- 0.016918773257299152
- 0.019342436425286075
- 0.024194809166289133
- 0.029053926970663335
- 0.03879247787862552
- 0.04855825021473061
- 0.058351406639679346
- 0.07802053051498409
- 0.1578260696927979
- 0.3231596700672531
- 3989.910512384025
target_epsilon: 1.0
task: sentiment
test_size: 39077
timeframe_days: 1
total_time: 35.68916893005371
train_size: 64934
training_accuracy_epochs:
- 0.6360343905443645
- 0.6359116145260426
- 0.6383671078892702
- 0.6440454405315673
- 0.6472068883437478
- 0.6550337790784256
- 0.6632596807585237
- 0.6719459904491573
- 0.6752302188899636
- 0.6801105125174338
- 0.6814303381666953
- 0.6873849139687764
- 0.6879987871449297
- 0.6933701812233055
- 0.6914671745089537
training_loss_epochs:
- 0.6858897097202954
- 0.6596971529623421
- 0.6418106414336526
- 0.6302612977133272
- 0.6254334848230056
- 0.6170415548988468
- 0.6088043454602279
- 0.6037692651564245
- 0.6003096861075301
- 0.5948367607856982
- 0.5940177200248887
- 0.5904445481893107
- 0.5908344157492917
- 0.5875492914276228
- 0.5899626187856685
training_time: 13.174007654190063
user_level: 1
validation_accuracy_epochs:
- 0.6525806139593255
- 0.6535768786521807
- 0.6582191913095239
- 0.6581500017479675
- 0.6683271184359512
- 0.6767331010674777
- 0.6848139011696593
- 0.6916632252196743
- 0.6914833424842521
- 0.6890203585363415
- 0.7014113893247631
- 0.7005119854456758
- 0.7028711952575265
- 0.7048291302707097
- 0.6983326583692472
validation_loss_epochs:
- 0.659395788630394
- 0.6460778778546477
- 0.6239843148074738
- 0.6260413372353332
- 0.6100143978040512
- 0.5988070246291487
- 0.5941280053086477
- 0.5860809683799744
- 0.5867568687216876
- 0.5888914163798502
- 0.5768243637803483
- 0.578021087058603
- 0.5773651444748656
- 0.57673560103325
- 0.5873884370882217
virtual_batch_multiplier: 0
vocab_size: 10000
