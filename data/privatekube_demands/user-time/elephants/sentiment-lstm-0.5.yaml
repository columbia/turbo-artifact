accuracy: 0.7665805620016511
adaptive_batch_size: 1
alphas:
- 1.5
- 1.75
- 2
- 2.5
- 3
- 4
- 5
- 6
- 8
- 16
- 32
- 64
batch_size: 403
best_alpha: 64.0
delta: 1.0e-09
device: cuda
dp: 1
dp_eval: 0
dropout: 0.25
dynamic_clipping: 0
embedding_dim: 100
epsilon: 0.4958751793510453
hidden_dim: 40
hidden_dim_1: 240
hidden_dim_2: 195
learning_rate: 0.01
learning_rate_scheduler: 1
loss: 0.6374141684512502
max_grad_norm: 1.0
max_text_len: 50
model: lstm
n_blocks: 1000
n_blocks_test: 200
n_epochs: 15
n_train_users: 162615
n_trainable_parameters: 22761
n_workers: 6
noise: 2.7870718383789064
non_dp_batch_size: 256
per_layer_clipping: 0
rdp_epsilons:
- 0.0038249662867428924
- 0.00446285680268943
- 0.00510086048915302
- 0.006377207843508023
- 0.007654008759956539
- 0.010208972613092728
- 0.0127657547299252
- 0.015324357798219421
- 0.020447037572691357
- 0.04101113675646396
- 0.08249615215484596
- 0.16693445178046737
target_epsilon: 0.5
task: sentiment
test_size: 39077
timeframe_days: 1
total_time: 393.22381114959717
train_size: 297910
training_accuracy_epochs:
- 0.6441083877317367
- 0.6601481394791425
- 0.6812491869512326
- 0.6969995461681641
- 0.7218811704266456
- 0.7280815654889525
- 0.7305260118716408
- 0.7378593479137563
- 0.7392201107134002
- 0.7368310803810952
- 0.7302920345041356
- 0.7372497771277321
- 0.7421386672308664
- 0.7413135903053188
- 0.742557364273308
training_loss_epochs:
- 0.7198007231018975
- 0.7590829923785946
- 0.7411770248235603
- 0.7436149073002061
- 0.7141862056095606
- 0.7100245897882334
- 0.7158757593140709
- 0.706522854622777
- 0.7001368978774873
- 0.7005263571407896
- 0.7175884280843711
- 0.7040323649091697
- 0.695625776688455
- 0.695153651698943
- 0.6891897931584058
training_time: 365.43029594421387
user_level: 1
validation_accuracy_epochs:
- 0.6532370809352759
- 0.6963606278101603
- 0.7062560988195015
- 0.7173622033812783
- 0.7411008314652876
- 0.7499887112415198
- 0.7541469299432003
- 0.7502293388048807
- 0.7607714822798064
- 0.7609820221409653
- 0.7452590339111559
- 0.7632528687968398
- 0.7658620910211043
- 0.7550868391990662
- 0.7609068317846819
validation_loss_epochs:
- 0.7203042091745319
- 0.7036424116654829
- 0.6894426273577141
- 0.6959746100685813
- 0.6589534914854801
- 0.6799372055313804
- 0.6741826173030969
- 0.6806086952036078
- 0.621805008613702
- 0.6449352177706632
- 0.6861796613895532
- 0.6334142892649679
- 0.636197976993792
- 0.6887051318631028
- 0.6442327734195825
virtual_batch_multiplier: 0
vocab_size: 10000
