accuracy: 0.6029671385772246
adaptive_batch_size: 1
alphas:
- 1.5
- 1.75
- 2
- 2.5
- 3
- 4
- 5
- 6
- 8
- 16
- 32
- 64
batch_size: 295
best_alpha: 64.0
delta: 1.0e-09
device: cuda
dp: 1
dp_eval: 0
dropout: 0.25
dynamic_clipping: 0
embedding_dim: 100
epsilon: 0.4974676310206343
hidden_dim: 100
hidden_dim_1: 185
hidden_dim_2: 150
learning_rate: 0.01
learning_rate_scheduler: 1
loss: 1.6774561700964332
max_grad_norm: 1.0
max_text_len: 60
model: feedforward
n_blocks: 500
n_blocks_test: 200
n_epochs: 15
n_train_users: 87174
n_trainable_parameters: 48246
n_workers: 6
noise: 3.214313659667969
non_dp_batch_size: 256
per_layer_clipping: 0
rdp_epsilons:
- 0.003861693504170205
- 0.004505708054836077
- 0.0051498365762135834
- 0.006438436124562311
- 0.007727492485084684
- 0.010306977019999792
- 0.012888292847546253
- 0.015471442640644584
- 0.020643254846442704
- 0.04140440121467214
- 0.08328596661352614
- 0.16852690345005633
target_epsilon: 0.5
task: product
test_size: 39077
timeframe_days: 1
total_time: 50.45608448982239
train_size: 165215
training_accuracy_epochs:
- 0.542039637444383
- 0.6346566984208963
- 0.6457224833763252
- 0.6455960845543166
- 0.6432634200079966
- 0.6496294076159849
- 0.6552140104568611
- 0.6581442028789197
- 0.6590749702211154
- 0.6623728725869776
- 0.6640505536127899
- 0.6637747710033999
- 0.66423440666522
- 0.6645101919012555
- 0.6649238645020178
training_loss_epochs:
- 1.595930979615551
- 1.3430205029956366
- 1.3607160477314966
- 1.4298752709970637
- 1.4931895793494532
- 1.5809388326386273
- 1.5541218143398479
- 1.5107873480198748
- 1.4926682839959355
- 1.4612333273483535
- 1.4513477858850512
- 1.4479329242544658
- 1.4455312813742687
- 1.4428161584724815
- 1.4361143401113607
training_time: 25.452975511550903
user_level: 1
validation_accuracy_epochs:
- 0.5615933789147272
- 0.5762826416227552
- 0.5875509646203783
- 0.5827298740545909
- 0.587719636493259
- 0.5873691876729329
- 0.6002996709611681
- 0.6012920631302727
- 0.6016687062051561
- 0.606476698981391
- 0.6069155746036106
- 0.604105450047387
- 0.6053287386894226
- 0.6080455170737372
- 0.6060378193855286
validation_loss_epochs:
- 1.5209094709820217
- 1.5214060174094306
- 1.5822472466362847
- 1.7838554912143283
- 1.6966493262184992
- 1.943746468755934
- 1.7254984696706137
- 1.7092006233003405
- 1.6686353868908352
- 1.6683123111724854
- 1.6568344646030002
- 1.6680353429582384
- 1.6537914276123047
- 1.6485267241795858
- 1.6530366155836318
virtual_batch_multiplier: 0
vocab_size: 10000
