accuracy: 0.6002346695083933
adaptive_batch_size: 1
alphas:
- 1.5
- 1.75
- 2
- 2.5
- 3
- 4
- 5
- 6
- 8
- 16
- 32
- 64
batch_size: 403
best_alpha: 64.0
delta: 1.0e-09
device: cuda
dp: 1
dp_eval: 0
dropout: 0.25
dynamic_clipping: 0
embedding_dim: 100
epsilon: 0.4958751793510453
hidden_dim: 100
hidden_dim_1: 240
hidden_dim_2: 195
learning_rate: 0.01
learning_rate_scheduler: 1
loss: 1.2654570414847934
max_grad_norm: 1.0
max_text_len: 75
model: bow
n_blocks: 1000
n_blocks_test: 200
n_epochs: 15
n_train_users: 162615
n_trainable_parameters: 1111
n_workers: 6
noise: 2.7870718383789064
non_dp_batch_size: 256
per_layer_clipping: 0
rdp_epsilons:
- 0.0038249662867428924
- 0.00446285680268943
- 0.00510086048915302
- 0.006377207843508023
- 0.007654008759956539
- 0.010208972613092728
- 0.0127657547299252
- 0.015324357798219421
- 0.020447037572691357
- 0.04101113675646396
- 0.08249615215484596
- 0.16693445178046737
target_epsilon: 0.5
task: product
test_size: 39077
timeframe_days: 1
total_time: 50.56816577911377
train_size: 297910
training_accuracy_epochs:
- 0.5363803699002521
- 0.6191836598493325
- 0.6395766195233348
- 0.6516326021024075
- 0.6577344813358695
- 0.6634053485860896
- 0.6674506903877921
- 0.6706340110331552
- 0.6724319415116132
- 0.674131354682203
- 0.675079577614001
- 0.6762433065374199
- 0.6776163839820597
- 0.6781274380518248
- 0.6799746263707542
training_loss_epochs:
- 1.517704273867548
- 1.2772905418358134
- 1.2044112593601122
- 1.1668140005237115
- 1.1410914345947152
- 1.1170019852020605
- 1.1006951950324084
- 1.089079476911436
- 1.0779596141195178
- 1.067033092378091
- 1.0569007025463113
- 1.050242278623226
- 1.042797202064145
- 1.0372548118122753
- 1.029478751252366
training_time: 22.9795503616333
user_level: 1
validation_accuracy_epochs:
- 0.5241521849776759
- 0.5507105724378065
- 0.5727799047123302
- 0.5766523751345548
- 0.5803368633443658
- 0.5893225037690365
- 0.5932400858763492
- 0.5933303218899351
- 0.5996390653379036
- 0.5955936493295612
- 0.5977216236519091
- 0.5998947204965533
- 0.5994134852380464
- 0.5988946484796929
- 0.6015113881140044
validation_loss_epochs:
- 1.5918925097494414
- 1.4817197431217541
- 1.425639838883371
- 1.3961829163811423
- 1.36585077011224
- 1.3473681500463774
- 1.3356868714997263
- 1.3218923445903894
- 1.3024160572976777
- 1.298590595071966
- 1.2821385896567143
- 1.2695721604607322
- 1.2699154940518467
- 1.260516968640414
- 1.260984926512747
virtual_batch_multiplier: 0
vocab_size: 10000
