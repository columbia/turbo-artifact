accuracy: 0.721325859688876
adaptive_batch_size: 1
alphas:
- 1.5
- 1.75
- 2
- 2.5
- 3
- 4
- 5
- 6
- 8
- 16
- 32
- 64
batch_size: 172
best_alpha: 6.0
delta: 1.0e-09
device: cuda
dp: 1
dp_eval: 0
dropout: 0.25
dynamic_clipping: 0
embedding_dim: 100
epsilon: 4.973310775959097
hidden_dim: 100
hidden_dim_1: 150
hidden_dim_2: 110
learning_rate: 0.01
learning_rate_scheduler: 1
loss: 0.9531558268425757
max_grad_norm: 1.0
max_text_len: 30
model: feedforward
n_blocks: 100
n_blocks_test: 200
n_epochs: 15
n_trainable_parameters: 31871
n_workers: 6
noise: 0.8721129608154297
non_dp_batch_size: 256
per_layer_clipping: 0
rdp_epsilons:
- 0.17404449639352534
- 0.2044329298793226
- 0.235262877337346
- 0.2983364717875588
- 0.3634716294305238
- 0.5010911308607984
- 0.6519709938267084
- 0.8286576085698144
- 6.459902451472978
- 12957.974722602235
- 40552.514694284815
- 95044.6177921964
target_epsilon: 5.0
task: sentiment
test_size: 39077
timeframe_days: 0
total_time: 39.595940828323364
train_size: 29727
training_accuracy_epochs:
- 0.6539007584715999
- 0.6852690626022427
- 0.710214972149494
- 0.7145416379667991
- 0.7174148136793181
- 0.7214372573896896
- 0.7219442888054737
- 0.7232963720033335
- 0.7245808475932409
- 0.7252230890268503
- 0.7240400151457898
- 0.7244456403477247
- 0.7247836617536323
- 0.7250878786624864
- 0.724885069353636
training_loss_epochs:
- 0.8220747612243475
- 0.8649422952602076
- 0.8941780450039132
- 0.953454174274622
- 0.9758672634529513
- 0.9231632982575616
- 0.9236864263928214
- 0.9224662857000218
- 0.9264638732339061
- 0.9087608872457992
- 0.9157336350790289
- 0.9185871124960655
- 0.9144303826398628
- 0.9174761189970859
- 0.9175858282765676
training_time: 17.06997299194336
user_level: 0
validation_accuracy_epochs:
- 0.6554285436868668
- 0.6959039984565032
- 0.7135692811325977
- 0.7210443670812406
- 0.7175120350561643
- 0.7142638517053503
- 0.7195908811531568
- 0.7182903917212236
- 0.7217607898147482
- 0.7199248059799797
- 0.7201749478515825
- 0.7210722949944044
- 0.7209399397435942
- 0.7209399405278658
- 0.7211147962432158
validation_loss_epochs:
- 0.9471140386242616
- 0.9557565372241171
- 0.9717041669707549
- 0.9060437718504354
- 0.9004706810963782
- 1.0615814626216888
- 0.9407302423527366
- 0.9215357201664072
- 0.8927813282138423
- 0.9498982774583917
- 0.9591349614293951
- 0.9399813758699518
- 0.9506089201098994
- 0.9483793581786909
- 0.946861960385975
virtual_batch_multiplier: 0
vocab_size: 10000
