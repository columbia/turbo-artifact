accuracy: 0.6072901851171023
adaptive_batch_size: 1
alphas:
- 1.5
- 1.75
- 2
- 2.5
- 3
- 4
- 5
- 6
- 8
- 16
- 32
- 64
batch_size: 254
best_alpha: 64.0
delta: 1.0e-09
device: cuda
dp: 1
dp_eval: 0
dropout: 0.25
dynamic_clipping: 0
embedding_dim: 100
epsilon: 0.4990900195627615
hidden_dim: 100
hidden_dim_1: 185
hidden_dim_2: 150
learning_rate: 0.01
learning_rate_scheduler: 1
loss: 1.5544848186629159
max_grad_norm: 1.0
max_text_len: 60
model: feedforward
n_blocks: 200
n_blocks_test: 200
n_epochs: 15
n_trainable_parameters: 48246
n_workers: 6
noise: 3.4279345703125
non_dp_batch_size: 256
per_layer_clipping: 0
rdp_epsilons:
- 0.0038983752849830466
- 0.004548509432567016
- 0.005198759417014252
- 0.006499606978737289
- 0.007800918299607766
- 0.01040493357088873
- 0.013010807943208334
- 0.015618544135188803
- 0.02083961288459652
- 0.04179890880842762
- 0.08408224347172387
- 0.17014929199218354
target_epsilon: 0.5
task: product
test_size: 39077
timeframe_days: 0
total_time: 43.99477529525757
train_size: 64934
training_accuracy_epochs:
- 0.4322525825132342
- 0.5377026318335065
- 0.5567083476805219
- 0.5634398607646718
- 0.567515822835997
- 0.5712521224629645
- 0.5755596714861253
- 0.5775667739849465
- 0.5792496512917912
- 0.581704493597442
- 0.5831712194517547
- 0.5828161176513224
- 0.5827080457818274
- 0.5832484182189492
- 0.5832792965804829
training_loss_epochs:
- 1.7954441631541533
- 1.5591891494451784
- 1.5909624992632398
- 1.6390111394957
- 1.6569443165087232
- 1.7227705198175767
- 1.7080127762813193
- 1.6738258848003313
- 1.655123748031317
- 1.6383822628096039
- 1.6303185673320995
- 1.6291570065068264
- 1.623627758961098
- 1.619898499694525
- 1.6215262698192223
training_time: 20.657962560653687
user_level: 0
validation_accuracy_epochs:
- 0.5491368816449091
- 0.5678460884552735
- 0.5829968337829297
- 0.5883765747913947
- 0.5976575704721304
- 0.5951738036595858
- 0.6048417630103918
- 0.6071888288626304
- 0.6089785718000852
- 0.6102530509233475
- 0.6114728439312714
- 0.6097546082276565
- 0.6097903652833059
- 0.6114013447211339
- 0.6108271926641464
validation_loss_epochs:
- 1.5058419016691356
- 1.5310566952595344
- 1.547484040260315
- 1.565947881111732
- 1.6489813946760619
- 1.710335190479572
- 1.5873844210918133
- 1.568549484014511
- 1.5304420292377472
- 1.5463526776203742
- 1.5358485602415526
- 1.5448406430391164
- 1.5440877309212317
- 1.5307040145763984
- 1.5324804507769072
virtual_batch_multiplier: 0
vocab_size: 10000
