accuracy: 0.766884728481895
adaptive_batch_size: 1
alphas:
- 1.5
- 1.75
- 2
- 2.5
- 3
- 4
- 5
- 6
- 8
- 16
- 32
- 64
batch_size: 172
best_alpha: 6.0
delta: 1.0e-09
device: cuda
dp: 1
dp_eval: 0
dropout: 0.25
dynamic_clipping: 0
embedding_dim: 100
epsilon: 4.973310775959097
hidden_dim: 40
hidden_dim_1: 240
hidden_dim_2: 195
learning_rate: 0.01
learning_rate_scheduler: 1
loss: 0.6829464102261945
max_grad_norm: 1.0
max_text_len: 50
model: lstm
n_blocks: 100
n_blocks_test: 200
n_epochs: 15
n_trainable_parameters: 22761
n_workers: 6
noise: 0.8721129608154297
non_dp_batch_size: 256
per_layer_clipping: 0
rdp_epsilons:
- 0.17404449639352534
- 0.2044329298793226
- 0.235262877337346
- 0.2983364717875588
- 0.3634716294305238
- 0.5010911308607984
- 0.6519709938267084
- 0.8286576085698144
- 6.459902451472978
- 12957.974722602235
- 40552.514694284815
- 95044.6177921964
target_epsilon: 5.0
task: sentiment
test_size: 39077
timeframe_days: 0
total_time: 196.08193850517273
train_size: 29727
training_accuracy_epochs:
- 0.6492360745405041
- 0.653123311871706
- 0.6683342335529106
- 0.7142036200262779
- 0.7397241741418839
- 0.7415494856446289
- 0.7568280145872471
- 0.7613912942104561
- 0.7720051383556321
- 0.7718699324962704
- 0.7757571675749713
- 0.7752163320086723
- 0.7690305605877278
- 0.7785289360340252
- 0.7759937831135684
training_loss_epochs:
- 0.6914611004812773
- 0.7123110744842264
- 0.7597288804691892
- 0.7262989802415981
- 0.6842188516328501
- 0.6633449841377347
- 0.671010492152946
- 0.6650207526115484
- 0.6563100844275119
- 0.6616538712798163
- 0.6463624789964321
- 0.6393420866062475
- 0.6511942860345508
- 0.6335809102585149
- 0.6347360612694607
training_time: 170.02984189987183
user_level: 0
validation_accuracy_epochs:
- 0.6534602022484729
- 0.6532367781588906
- 0.6836568195568887
- 0.7427847706957867
- 0.711920299812367
- 0.746081531047821
- 0.7056825600172344
- 0.7599971380672956
- 0.7556913095085245
- 0.7545231768959447
- 0.7613680527398461
- 0.7567149479138223
- 0.7657479455596522
- 0.7641706027482685
- 0.75997042263809
validation_loss_epochs:
- 0.7275699173149309
- 0.7283258751819008
- 0.8188637024477908
- 0.707375459765133
- 0.6907029544052324
- 0.6548318894285905
- 0.8567020689186297
- 0.6984269101368753
- 0.7360531840669481
- 0.7303971310979441
- 0.7349120590247606
- 0.7271684800323687
- 0.6914163176950655
- 0.6721520659170652
- 0.7043827454510488
virtual_batch_multiplier: 0
vocab_size: 10000
