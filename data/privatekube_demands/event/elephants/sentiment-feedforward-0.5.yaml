accuracy: 0.7126037788081478
adaptive_batch_size: 1
alphas:
- 1.5
- 1.75
- 2
- 2.5
- 3
- 4
- 5
- 6
- 8
- 16
- 32
- 64
batch_size: 254
best_alpha: 64.0
delta: 1.0e-09
device: cuda
dp: 1
dp_eval: 0
dropout: 0.25
dynamic_clipping: 0
embedding_dim: 100
epsilon: 0.4990900195627615
hidden_dim: 100
hidden_dim_1: 150
hidden_dim_2: 110
learning_rate: 0.01
learning_rate_scheduler: 1
loss: 0.9918347484879679
max_grad_norm: 1.0
max_text_len: 30
model: feedforward
n_blocks: 200
n_blocks_test: 200
n_epochs: 15
n_trainable_parameters: 31871
n_workers: 6
noise: 3.4279345703125
non_dp_batch_size: 256
per_layer_clipping: 0
rdp_epsilons:
- 0.0038983752849830466
- 0.004548509432567016
- 0.005198759417014252
- 0.006499606978737289
- 0.007800918299607766
- 0.01040493357088873
- 0.013010807943208334
- 0.015618544135188803
- 0.02083961288459652
- 0.04179890880842762
- 0.08408224347172387
- 0.17014929199218354
target_epsilon: 0.5
task: sentiment
test_size: 39077
timeframe_days: 0
total_time: 43.825742959976196
train_size: 64934
training_accuracy_epochs:
- 0.6590087929192712
- 0.6616489034073025
- 0.6813648247251324
- 0.6969430285341599
- 0.7093098703552695
- 0.712073496276257
- 0.7122742056846618
- 0.714250430873796
- 0.7143430642053192
- 0.7150069545297062
- 0.7148062434850955
- 0.7148525598002415
- 0.7149143162895651
- 0.7148834387461345
- 0.7147753638379714
training_loss_epochs:
- 0.8638298317497852
- 0.9722556464812335
- 0.9404828733088924
- 0.9360965618900224
- 0.9793396292948255
- 0.9686211123185999
- 0.9694900199478748
- 0.9618223396002078
- 0.9544687712893767
- 0.954692994145786
- 0.9567346860380733
- 0.9536816517512003
- 0.9544611439985388
- 0.9577553442880219
- 0.9585861657180038
training_time: 21.442598819732666
user_level: 0
validation_accuracy_epochs:
- 0.653377156991225
- 0.6682692215992854
- 0.6871845309550946
- 0.7038053572177887
- 0.6969555536141763
- 0.7056224369085752
- 0.705092456478339
- 0.706303840646377
- 0.7047580629587173
- 0.7031912505626678
- 0.7048337723200138
- 0.7046781457387484
- 0.7055551375334079
- 0.7047896133019373
- 0.7053237958596303
validation_loss_epochs:
- 0.9128933514540012
- 0.8653476708210431
- 0.8733718360845859
- 0.9143378379253241
- 1.1079707810511956
- 1.0115562711770718
- 1.0045677423477173
- 0.9523209757529773
- 0.9940819579821366
- 1.0060054235733473
- 0.9937890057380383
- 1.0030442739908512
- 0.9930788633915094
- 0.9963436092321689
- 0.9925525234295771
virtual_batch_multiplier: 0
vocab_size: 10000
