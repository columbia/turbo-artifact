accuracy: 0.7124867020991811
adaptive_batch_size: 1
alphas:
- 1.5
- 1.75
- 2
- 2.5
- 3
- 4
- 5
- 6
- 8
- 16
- 32
- 64
batch_size: 172
best_alpha: 32.0
delta: 1.0e-09
device: cuda
dp: 1
dp_eval: 0
dropout: 0.25
dynamic_clipping: 0
embedding_dim: 100
epsilon: 0.9975171431099421
hidden_dim: 100
hidden_dim_1: 240
hidden_dim_2: 195
learning_rate: 0.01
learning_rate_scheduler: 1
loss: 0.5683674608406267
max_grad_norm: 1.0
max_text_len: 50
model: bow
n_blocks: 100
n_blocks_test: 200
n_epochs: 15
n_trainable_parameters: 101
n_workers: 6
noise: 2.2072436523437498
non_dp_batch_size: 256
per_layer_clipping: 0
rdp_epsilons:
- 0.014748953604987722
- 0.017213164399589774
- 0.019679111189983577
- 0.024616223150530914
- 0.029560310330249355
- 0.03946949431809528
- 0.04940683209710537
- 0.05937249430432911
- 0.07938948316939985
- 0.16062576242279583
- 0.32902469675683216
- 3443.192485535799
target_epsilon: 1.0
task: sentiment
test_size: 39077
timeframe_days: 0
total_time: 36.26720404624939
train_size: 29727
training_accuracy_epochs:
- 0.6529204978845841
- 0.6537317481151846
- 0.6544415926517442
- 0.6579908070176147
- 0.6676919938519944
- 0.6765481344489164
- 0.6839845849331035
- 0.694463214555452
- 0.6959843112285747
- 0.7003785791092141
- 0.7028461271940276
- 0.7038263869146968
- 0.7054826852887176
- 0.7082544558270033
- 0.7089304989853571
training_loss_epochs:
- 0.6741100144247676
- 0.6452605897604033
- 0.6280833981757941
- 0.6185750115749448
- 0.6049779029779656
- 0.597501463148483
- 0.5904054078598355
- 0.5821815228392911
- 0.5822974427841431
- 0.5777381558057874
- 0.5762185703876407
- 0.5758186278994694
- 0.5733680333509001
- 0.5706956649935523
- 0.5705843349528867
training_time: 13.231873273849487
user_level: 0
validation_accuracy_epochs:
- 0.6531529897137692
- 0.6535160557219857
- 0.6535427727197346
- 0.6676405158482099
- 0.6675154433438653
- 0.67544345714544
- 0.6930103796093088
- 0.6916054620554573
- 0.6963836393858257
- 0.699555325664972
- 0.6977958428232294
- 0.6994375461026242
- 0.703560009598732
- 0.7006530306841198
- 0.7103623857623652
validation_loss_epochs:
- 0.6605796986504605
- 0.6575828696552076
- 0.654007688164711
- 0.6045093081499401
- 0.6108569800853729
- 0.5990949602503526
- 0.5835099102635133
- 0.5876711740305549
- 0.5835293186338324
- 0.5819487140366906
- 0.5865451207286433
- 0.585593907456649
- 0.583337266194193
- 0.5873697792228899
- 0.5725693843866649
virtual_batch_multiplier: 0
vocab_size: 10000
