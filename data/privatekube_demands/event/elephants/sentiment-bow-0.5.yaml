accuracy: 0.7109697592722906
adaptive_batch_size: 1
alphas:
- 1.5
- 1.75
- 2
- 2.5
- 3
- 4
- 5
- 6
- 8
- 16
- 32
- 64
batch_size: 254
best_alpha: 64.0
delta: 1.0e-09
device: cuda
dp: 1
dp_eval: 0
dropout: 0.25
dynamic_clipping: 0
embedding_dim: 100
epsilon: 0.4990900195627615
hidden_dim: 100
hidden_dim_1: 240
hidden_dim_2: 195
learning_rate: 0.01
learning_rate_scheduler: 1
loss: 0.5655958727969752
max_grad_norm: 1.0
max_text_len: 50
model: bow
n_blocks: 200
n_blocks_test: 200
n_epochs: 15
n_trainable_parameters: 101
n_workers: 6
noise: 3.4279345703125
non_dp_batch_size: 256
per_layer_clipping: 0
rdp_epsilons:
- 0.0038983752849830466
- 0.004548509432567016
- 0.005198759417014252
- 0.006499606978737289
- 0.007800918299607766
- 0.01040493357088873
- 0.013010807943208334
- 0.015618544135188803
- 0.02083961288459652
- 0.04179890880842762
- 0.08408224347172387
- 0.17014929199218354
target_epsilon: 0.5
task: sentiment
test_size: 39077
timeframe_days: 0
total_time: 38.42746114730835
train_size: 64934
training_accuracy_epochs:
- 0.6576501379994785
- 0.6607688679414637
- 0.6640574268266266
- 0.671205797849917
- 0.6813339446105209
- 0.6893623581119612
- 0.6980700936971926
- 0.703072411406274
- 0.7040296461067947
- 0.7065771229126874
- 0.7097730470638649
- 0.7109155495961507
- 0.7116720753557542
- 0.713648298441195
- 0.7149760734801199
training_loss_epochs:
- 0.659167161174849
- 0.6288121948055193
- 0.6102515173893349
- 0.5982753260462892
- 0.589434601278866
- 0.5821437847380545
- 0.5760876232502508
- 0.5715207165362788
- 0.5701347577805612
- 0.5686971508989147
- 0.5661609629789989
- 0.563721906671337
- 0.5640919567323198
- 0.5606533560098387
- 0.5595580556813409
training_time: 16.000752449035645
user_level: 0
validation_accuracy_epochs:
- 0.6520374784102807
- 0.6550070631962556
- 0.6663680214148301
- 0.6723534499223416
- 0.6832832739903376
- 0.6863033290092762
- 0.6892645026628788
- 0.6988125879030961
- 0.69976950608767
- 0.698019721187078
- 0.6998641433624121
- 0.7013152803366001
- 0.7071366711304738
- 0.7080536244007257
- 0.7067539038566443
validation_loss_epochs:
- 0.6475833562704233
- 0.6242059847483268
- 0.6049618927332071
- 0.6026713997125626
- 0.5920237761277419
- 0.5908341671411808
- 0.5957420365168498
- 0.5776446209504054
- 0.5804503502754065
- 0.582690954208374
- 0.5807508568351085
- 0.5807542239244168
- 0.5758513040267504
- 0.570015373138281
- 0.5708412785942738
virtual_batch_multiplier: 0
vocab_size: 10000
