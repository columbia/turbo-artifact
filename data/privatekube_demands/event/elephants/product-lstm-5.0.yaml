accuracy: 0.6331712201044157
adaptive_batch_size: 1
alphas:
- 1.5
- 1.75
- 2
- 2.5
- 3
- 4
- 5
- 6
- 8
- 16
- 32
- 64
batch_size: 254
best_alpha: 6.0
delta: 1.0e-09
device: cuda
dp: 1
dp_eval: 0
dropout: 0.25
dynamic_clipping: 0
embedding_dim: 100
epsilon: 4.963720257185697
hidden_dim: 40
hidden_dim_1: 240
hidden_dim_2: 195
learning_rate: 0.01
learning_rate_scheduler: 1
loss: 1.287758301991921
max_grad_norm: 1.0
max_text_len: 30
model: lstm
n_blocks: 200
n_blocks_test: 200
n_epochs: 15
n_trainable_parameters: 23171
n_workers: 6
noise: 0.8034490966796874
non_dp_batch_size: 256
per_layer_clipping: 0
rdp_epsilons:
- 0.16038222740589758
- 0.18845701756355454
- 0.21696989492019264
- 0.2754179586049191
- 0.3359868809141369
- 0.4651375293776605
- 0.6113782000371601
- 0.819067089796415
- 182.1770374496527
- 24784.203290658137
- 72916.71393930189
- 168069.91123696003
target_epsilon: 5.0
task: product
test_size: 39077
timeframe_days: 0
total_time: 194.1005654335022
train_size: 64934
training_accuracy_epochs:
- 0.44092944036511816
- 0.5402037899868161
- 0.5549791497342726
- 0.5667747384192897
- 0.5757603844006857
- 0.5844835573551701
- 0.5883588113036811
- 0.5920487899406284
- 0.5963100220642837
- 0.600092638240141
- 0.6050023177090813
- 0.6078122615814209
- 0.6101127075214012
- 0.6114868014466529
- 0.6134475841241724
training_loss_epochs:
- 1.8084319932788027
- 1.6049040336234897
- 1.5600608465718289
- 1.528336883058735
- 1.5005792253157673
- 1.4735348210615271
- 1.4642318230049283
- 1.4478979582880058
- 1.4287188385047165
- 1.4130678144155764
- 1.4030547843259924
- 1.382179222387426
- 1.3800677201327156
- 1.3706658555012123
- 1.366263970674253
training_time: 167.30971145629883
user_level: 0
validation_accuracy_epochs:
- 0.5411156473251489
- 0.585312355023164
- 0.5840483880960025
- 0.5980592587819467
- 0.608271925495221
- 0.6069301469967916
- 0.6135128553097065
- 0.6250925350647706
- 0.6321105853869364
- 0.6292777084387265
- 0.6198726376661887
- 0.6322178473839393
- 0.6341905548022344
- 0.6339234606577799
- 0.6306678561063913
validation_loss_epochs:
- 1.5335851197059338
- 1.4214933514595032
- 1.3975310256847968
- 1.4304699553893163
- 1.3975215302063868
- 1.4240451684364905
- 1.376413379724209
- 1.350395502952429
- 1.3156420863591707
- 1.372732971723263
- 1.341969256217663
- 1.3004780938992133
- 1.3417074863727276
- 1.3041619933568513
- 1.3167521518010359
virtual_batch_multiplier: 0
vocab_size: 10000
