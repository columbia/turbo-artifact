accuracy: 0.6172929901581306
adaptive_batch_size: 1
alphas:
- 1.5
- 1.75
- 2
- 2.5
- 3
- 4
- 5
- 6
- 8
- 16
- 32
- 64
batch_size: 254
best_alpha: 6.0
delta: 1.0e-09
device: cuda
dp: 1
dp_eval: 0
dropout: 0.25
dynamic_clipping: 0
embedding_dim: 100
epsilon: 4.963720257185697
hidden_dim: 100
hidden_dim_1: 240
hidden_dim_2: 195
learning_rate: 0.01
learning_rate_scheduler: 1
loss: 1.1670353474555077
max_grad_norm: 1.0
max_text_len: 75
model: bow
n_blocks: 200
n_blocks_test: 200
n_epochs: 15
n_trainable_parameters: 1111
n_workers: 6
noise: 0.8034490966796874
non_dp_batch_size: 256
per_layer_clipping: 0
rdp_epsilons:
- 0.16038222740589758
- 0.18845701756355454
- 0.21696989492019264
- 0.2754179586049191
- 0.3359868809141369
- 0.4651375293776605
- 0.6113782000371601
- 0.819067089796415
- 182.1770374496527
- 24784.203290658137
- 72916.71393930189
- 168069.91123696003
target_epsilon: 5.0
task: product
test_size: 39077
timeframe_days: 0
total_time: 40.57943081855774
train_size: 64934
training_accuracy_epochs:
- 0.4473830439588603
- 0.5306005791121838
- 0.5499459555336074
- 0.5608615050128862
- 0.5671915961246864
- 0.5727034107142803
- 0.576316194674548
- 0.5786012039465063
- 0.5814265865905612
- 0.5833256134799882
- 0.5849776134771459
- 0.5878956315564174
- 0.5892388465357762
- 0.5917091266781676
- 0.5934692025184631
training_loss_epochs:
- 1.7658678629819085
- 1.5416940978929108
- 1.4631603086695952
- 1.4117772200528313
- 1.379228300674289
- 1.3533421376172234
- 1.3293967578925339
- 1.3126827225965612
- 1.2985346976448509
- 1.2858158490237068
- 1.2742971237967997
- 1.2643694330664241
- 1.2560464662664077
- 1.2460171900543513
- 1.2398050700916963
training_time: 16.90385675430298
user_level: 0
validation_accuracy_epochs:
- 0.5443481115194467
- 0.56587337072079
- 0.5796613165965447
- 0.5883765724989084
- 0.5978804998672925
- 0.5951780126645014
- 0.5990350991487503
- 0.6042003218944256
- 0.6054874200087327
- 0.6047387157495205
- 0.6077587684759727
- 0.6078660258880029
- 0.6114959785571465
- 0.6145286525671299
- 0.6193069001803031
validation_loss_epochs:
- 1.5272234334395483
- 1.4190034224436834
- 1.35898573581989
- 1.314298457824267
- 1.2828146448502173
- 1.2604188804443066
- 1.2429791941092565
- 1.2217829754719367
- 1.2061625031324534
- 1.1987933699901288
- 1.188131041251696
- 1.1812505905444806
- 1.1691076732598817
- 1.1675005772939095
- 1.1585579812526703
virtual_batch_multiplier: 0
vocab_size: 10000
