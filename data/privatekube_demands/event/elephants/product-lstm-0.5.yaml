accuracy: 0.6103368739491886
adaptive_batch_size: 1
alphas:
- 1.5
- 1.75
- 2
- 2.5
- 3
- 4
- 5
- 6
- 8
- 16
- 32
- 64
batch_size: 406
best_alpha: 64.0
delta: 1.0e-09
device: cuda
dp: 1
dp_eval: 0
dropout: 0.25
dynamic_clipping: 0
embedding_dim: 100
epsilon: 0.4982933830142225
hidden_dim: 40
hidden_dim_1: 240
hidden_dim_2: 195
learning_rate: 0.01
learning_rate_scheduler: 1
loss: 1.3338937636503239
max_grad_norm: 1.0
max_text_len: 30
model: lstm
n_blocks: 500
n_blocks_test: 200
n_epochs: 15
n_trainable_parameters: 23171
n_workers: 6
noise: 2.7565545654296875
non_dp_batch_size: 256
per_layer_clipping: 0
rdp_epsilons:
- 0.003878918133040088
- 0.0045258126738190185
- 0.0051728239088993785
- 0.0064671967280191655
- 0.007762036975518741
- 0.010353121186908494
- 0.012946079353993127
- 0.015540914294639328
- 0.02073622580224798
- 0.04159311110455767
- 0.08367476730930011
- 0.16935265544364453
target_epsilon: 0.5
task: product
test_size: 39077
timeframe_days: 0
total_time: 272.5872812271118
train_size: 165215
training_accuracy_epochs:
- 0.4604576593677839
- 0.528482845924758
- 0.5372309349293779
- 0.5486726106094022
- 0.5534288508111033
- 0.5584277593590355
- 0.564215331902645
- 0.5669210498115699
- 0.5687410418916805
- 0.5721868912281074
- 0.5800249861378975
- 0.5803707826313714
- 0.5861037543841771
- 0.5866618843501424
- 0.5879298105028462
training_loss_epochs:
- 1.8043100129207368
- 1.6704758361642584
- 1.623335302463306
- 1.5944552260079408
- 1.5662258041316066
- 1.559633693671579
- 1.5582536514756715
- 1.5617852348999437
- 1.5490783241582033
- 1.5283594566025758
- 1.488802476763138
- 1.4839706649921212
- 1.4664343874442753
- 1.4696895101387513
- 1.4624787457470823
training_time: 247.30188155174255
user_level: 0
validation_accuracy_epochs:
- 0.5238885418935255
- 0.5608870423201359
- 0.5621602733929952
- 0.5776805913809574
- 0.5759946532321699
- 0.5867161804979498
- 0.5873308461723905
- 0.5817198211496527
- 0.5823959563717698
- 0.6032199624812964
- 0.5979074926087351
- 0.6007788632855271
- 0.6061352364944689
- 0.6038741415197199
- 0.6095510233532299
validation_loss_epochs:
- 1.717721498373783
- 1.5292380686962244
- 1.509612556659814
- 1.5191452286460183
- 1.5313336487972375
- 1.4405730818257187
- 1.4581523483449763
- 1.4800787875146577
- 1.4507047335306804
- 1.3993293191447402
- 1.4104791951901985
- 1.4497358618360576
- 1.3590376232609604
- 1.3895530592311511
- 1.3430859500711614
virtual_batch_multiplier: 0
vocab_size: 10000
