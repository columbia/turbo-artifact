accuracy: 0.8208735263232633
adaptive_batch_size: 1
alphas:
- 1.5
- 1.75
- 2
- 2.5
- 3
- 4
- 5
- 6
- 8
- 16
- 32
- 64
batch_size: 64
best_alpha: 64.0
delta: 1.0e-09
device: cuda
dp: 1
dp_eval: 0
dropout: 0.25
dynamic_clipping: 0
embedding_dim: 100
epsilon: 0.4964754382547129
hidden_dim: 100
hidden_dim_1: 240
hidden_dim_2: 195
learning_rate: 0.0005
learning_rate_scheduler: 1
loss: 0.7182578570254363
max_grad_norm: 1.0
max_text_len: 140
model: bert
n_blocks: 500
n_blocks_test: 200
n_epochs: 3
n_trainable_parameters: 855809
n_workers: 6
noise: 2.2933118987083434
non_dp_batch_size: 256
per_layer_clipping: 0
rdp_epsilons:
- 0.0010863953472721732
- 0.0012676243753162453
- 0.0014489000661624693
- 0.0018115915799192673
- 0.0021744701011820627
- 0.0029007889792253667
- 0.003627858338961546
- 0.004355679824961978
- 0.00581358578388006
- 0.011675627732768942
- 0.023548567593532334
- 0.16753471068413495
target_epsilon: 0.5
task: sentiment
test_size: 39786
timeframe_days: 0
total_time: 801.765677690506
train_size: 166581
training_accuracy_epochs:
- 0.6576131341275941
- 0.7177831956187548
- 0.8004299577248271
training_loss_epochs:
- 1.0441367925015164
- 0.8346117372230142
- 0.7270181590689777
training_time: 772.0349988937378
user_level: 0
validation_accuracy_epochs:
- 0.6639659169774789
- 0.799343235217608
- 0.8156443169483771
validation_loss_epochs:
- 0.9339290977670596
- 0.6762364758178592
- 0.7194792453486186
virtual_batch_multiplier: 6
vocab_size: 10000
