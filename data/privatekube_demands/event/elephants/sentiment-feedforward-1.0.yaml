accuracy: 0.7110641235322283
adaptive_batch_size: 1
alphas:
- 1.5
- 1.75
- 2
- 2.5
- 3
- 4
- 5
- 6
- 8
- 16
- 32
- 64
batch_size: 172
best_alpha: 32.0
delta: 1.0e-09
device: cuda
dp: 1
dp_eval: 0
dropout: 0.25
dynamic_clipping: 0
embedding_dim: 100
epsilon: 0.9975171431099421
hidden_dim: 100
hidden_dim_1: 150
hidden_dim_2: 110
learning_rate: 0.01
learning_rate_scheduler: 1
loss: 0.9426397218515998
max_grad_norm: 1.0
max_text_len: 30
model: feedforward
n_blocks: 100
n_blocks_test: 200
n_epochs: 15
n_trainable_parameters: 31871
n_workers: 6
noise: 2.2072436523437498
non_dp_batch_size: 256
per_layer_clipping: 0
rdp_epsilons:
- 0.014748953604987722
- 0.017213164399589774
- 0.019679111189983577
- 0.024616223150530914
- 0.029560310330249355
- 0.03946949431809528
- 0.04940683209710537
- 0.05937249430432911
- 0.07938948316939985
- 0.16062576242279583
- 0.32902469675683216
- 3443.192485535799
target_epsilon: 1.0
task: sentiment
test_size: 39077
timeframe_days: 0
total_time: 38.953999519348145
train_size: 29727
training_accuracy_epochs:
- 0.6534613315449205
- 0.6537993557231371
- 0.6665427268937577
- 0.6911506205797195
- 0.7054150842649992
- 0.7099107573198717
- 0.7122430998918622
- 0.7129191395848297
- 0.7138993958401125
- 0.7141022103470426
- 0.7140008037866548
- 0.7142712217430736
- 0.7144402324460274
- 0.7141360124183256
- 0.7143050206955089
training_loss_epochs:
- 0.849087881834008
- 0.9806855119938074
- 0.962990129756373
- 0.9368053269247676
- 0.9447254140016644
- 0.9374438212361447
- 0.9240212253359861
- 0.9328074864176816
- 0.9232850733191468
- 0.9165723639172177
- 0.9237915852735209
- 0.9190433683783509
- 0.9282059600186903
- 0.9300401300884956
- 0.9278038275796313
training_time: 16.864992141723633
user_level: 0
validation_accuracy_epochs:
- 0.6534322735510374
- 0.6584180915041974
- 0.6830023197751296
- 0.701278385363127
- 0.7044440053011242
- 0.7103975964219946
- 0.7040190069298995
- 0.7083029699952978
- 0.7121631542318746
- 0.7091529659534755
- 0.708992683573773
- 0.7091796790298662
- 0.709026680180901
- 0.7089708196489435
- 0.7094929618270773
validation_loss_epochs:
- 0.9081617319270184
- 0.8684543128076353
- 0.8870502239779422
- 0.977405657893733
- 0.9758208723444688
- 0.8851631173962041
- 0.9752463792499743
- 0.9506746428577524
- 0.9115534989457381
- 0.9412905267978969
- 0.9404884608168351
- 0.9453965817627153
- 0.9453862003589931
- 0.9431680409531844
- 0.9423746976413225
virtual_batch_multiplier: 0
vocab_size: 10000
