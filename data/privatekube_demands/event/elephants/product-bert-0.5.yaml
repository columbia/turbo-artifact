accuracy: 0.7238195720592879
adaptive_batch_size: 1
alphas:
- 1.5
- 1.75
- 2
- 2.5
- 3
- 4
- 5
- 6
- 8
- 16
- 32
- 64
batch_size: 64
best_alpha: 64.0
delta: 1.0e-09
device: cuda
dp: 1
dp_eval: 0
dropout: 0.25
dynamic_clipping: 0
embedding_dim: 100
epsilon: 0.49757849852990943
hidden_dim: 100
hidden_dim_1: 240
hidden_dim_2: 195
learning_rate: 0.0005
learning_rate_scheduler: 1
loss: 1.0079026356866505
max_grad_norm: 1.0
max_text_len: 140
model: bert
n_blocks: 2000
n_blocks_test: 200
n_epochs: 3
n_trainable_parameters: 858379
n_workers: 6
noise: 2.200210374593735
non_dp_batch_size: 256
per_layer_clipping: 0
rdp_epsilons:
- 0.0007061770800760314
- 0.0008239426905447544
- 0.00094172813781781
- 0.0011773586242561274
- 0.0014130686041739474
- 0.0018847272777150388
- 0.002356704616600719
- 0.002829001080062122
- 0.0037745532231103986
- 0.007569619386755013
- 0.015222252845984165
- 0.1686377709593315
target_epsilon: 0.5
task: product
test_size: 39786
timeframe_days: 0
total_time: 2411.192281961441
train_size: 514963
training_accuracy_epochs:
- 0.597771796544867
- 0.6872727908277405
- 0.7096130841411882
training_loss_epochs:
- 1.3082093297546253
- 1.082153984012368
- 1.0469179834125055
training_time: 2376.82062458992
user_level: 0
validation_accuracy_epochs:
- 0.6693853025253003
- 0.7065805288461539
- 0.7211753092706203
validation_loss_epochs:
- 1.0783558195600143
- 1.0161970509932592
- 0.9986854118223374
virtual_batch_multiplier: 11
vocab_size: 10000
