accuracy: 0.6004177211941063
adaptive_batch_size: 1
alphas:
- 1.5
- 1.75
- 2
- 2.5
- 3
- 4
- 5
- 6
- 8
- 16
- 32
- 64
batch_size: 254
best_alpha: 32.0
delta: 1.0e-09
device: cuda
dp: 1
dp_eval: 0
dropout: 0.25
dynamic_clipping: 0
embedding_dim: 100
epsilon: 0.9920475714879368
hidden_dim: 40
hidden_dim_1: 240
hidden_dim_2: 195
learning_rate: 0.01
learning_rate_scheduler: 1
loss: 1.4228342779271015
max_grad_norm: 1.0
max_text_len: 30
model: lstm
n_blocks: 200
n_blocks_test: 200
n_epochs: 15
n_trainable_parameters: 23171
n_workers: 6
noise: 1.8715536499023435
non_dp_batch_size: 256
per_layer_clipping: 0
rdp_epsilons:
- 0.014493339607875567
- 0.01691492246137224
- 0.019338234263818227
- 0.024190055491501994
- 0.029048825018887562
- 0.03878729627063078
- 0.04855382391067626
- 0.05834858573162823
- 0.07802353278004158
- 0.15788962226749753
- 0.32355512513482676
- 13402.763099975355
target_epsilon: 1.0
task: product
test_size: 39077
timeframe_days: 0
total_time: 180.64712071418762
train_size: 64934
training_accuracy_epochs:
- 0.4190520290358394
- 0.4796201924482981
- 0.5092017845780241
- 0.5244094405688492
- 0.530353551051196
- 0.5376563151677449
- 0.5435386670570748
- 0.5484792260562672
- 0.556276050268435
- 0.5546240493363025
- 0.5558591878881641
- 0.5595800465228511
- 0.5652153715199115
- 0.5656785509165596
- 0.5712829982533174
training_loss_epochs:
- 1.8848494501674877
- 1.7491569495668597
- 1.7312994662453147
- 1.704247703739241
- 1.6678071980382883
- 1.6459431774475994
- 1.61545363407509
- 1.594438741721359
- 1.576129800198125
- 1.5735670767578425
- 1.5606178152794932
- 1.556502604484558
- 1.5345927547006046
- 1.5196946335773842
- 1.5041708090726067
training_time: 155.72106385231018
user_level: 0
validation_accuracy_epochs:
- 0.5030368784299264
- 0.532591768182241
- 0.5499465717719152
- 0.5418286036986572
- 0.5615851460741117
- 0.5731585255035987
- 0.5801071742406259
- 0.574540260892648
- 0.5824311020282599
- 0.5751901223109319
- 0.579478341799516
- 0.5832281754567072
- 0.5912578243475693
- 0.5949508742644236
- 0.599043512573609
validation_loss_epochs:
- 1.5612028928903432
- 1.6016532732890203
- 1.5679088097352247
- 1.6123073353217199
- 1.5373491461460407
- 1.5332476267447839
- 1.5231209787038655
- 1.5043432827179248
- 1.4593462944030762
- 1.4443302704737737
- 1.4831648881618793
- 1.4530342404658978
- 1.4230037079407618
- 1.394748683159168
- 1.433591413956422
virtual_batch_multiplier: 0
vocab_size: 10000
