accuracy: 0.6212047793201565
adaptive_batch_size: 1
alphas:
- 1.5
- 1.75
- 2
- 2.5
- 3
- 4
- 5
- 6
- 8
- 16
- 32
- 64
batch_size: 406
best_alpha: 32.0
delta: 1.0e-09
device: cuda
dp: 1
dp_eval: 0
dropout: 0.25
dynamic_clipping: 0
embedding_dim: 100
epsilon: 0.9905773659710048
hidden_dim: 100
hidden_dim_1: 240
hidden_dim_2: 195
learning_rate: 0.01
learning_rate_scheduler: 1
loss: 1.1552374528855394
max_grad_norm: 1.0
max_text_len: 75
model: bow
n_blocks: 500
n_blocks_test: 200
n_epochs: 15
n_trainable_parameters: 1111
n_workers: 6
noise: 1.642674102783203
non_dp_batch_size: 256
per_layer_clipping: 0
rdp_epsilons:
- 0.012365452649447661
- 0.014430909619989052
- 0.016497671029719958
- 0.02063511462087298
- 0.024777798424544775
- 0.033078946955730874
- 0.041401238066290064
- 0.04974479444774085
- 0.06649620015387098
- 0.13437787519970515
- 0.32208491961789476
- 35047.64531257814
target_epsilon: 1.0
task: product
test_size: 39077
timeframe_days: 0
total_time: 48.422518730163574
train_size: 165215
training_accuracy_epochs:
- 0.4730337947386826
- 0.5452752936209364
- 0.5620313418909834
- 0.5712465614520857
- 0.5771372646386987
- 0.5809471133747711
- 0.5839500983653985
- 0.58624328504055
- 0.5893372709821598
- 0.5909085284019339
- 0.5936385156779453
- 0.5956223053591592
- 0.5978972926515663
- 0.599559554325536
- 0.6014341431591899
training_loss_epochs:
- 1.7004776165403168
- 1.4859711322291145
- 1.4121361081236101
- 1.367655678629288
- 1.3360879829364458
- 1.3129298134977594
- 1.2932383837958275
- 1.2792133019475513
- 1.2642404815833557
- 1.2538768834081189
- 1.2441896617118948
- 1.2337482439473344
- 1.2248993410265505
- 1.2168950661649844
- 1.2102004380648947
training_time: 23.567911386489868
user_level: 0
validation_accuracy_epochs:
- 0.5532827431505377
- 0.5780757349548917
- 0.5838184754053751
- 0.592770643306501
- 0.6019335515571363
- 0.6005242159872344
- 0.5986670400157119
- 0.6065786697647788
- 0.6037555969122684
- 0.6094061334927877
- 0.6120140769264915
- 0.6142532139113455
- 0.6145605444908142
- 0.6206764741377397
- 0.6198642362247814
validation_loss_epochs:
- 1.4688759139089873
- 1.3778421264706235
- 1.329832015615521
- 1.2879074233950991
- 1.2519917235229954
- 1.2442418770356611
- 1.2281799858266658
- 1.2083374984336621
- 1.209159847461816
- 1.185673601699598
- 1.172099510828654
- 1.1649902228153113
- 1.1585859674395937
- 1.1379823793064465
- 1.1534444346572414
virtual_batch_multiplier: 0
vocab_size: 10000
