accuracy: 0.6038125575203257
adaptive_batch_size: 1
alphas:
- 1.5
- 1.75
- 2
- 2.5
- 3
- 4
- 5
- 6
- 8
- 16
- 32
- 64
batch_size: 406
best_alpha: 64.0
delta: 1.0e-09
device: cuda
dp: 1
dp_eval: 0
dropout: 0.25
dynamic_clipping: 0
embedding_dim: 100
epsilon: 0.4982933830142225
hidden_dim: 100
hidden_dim_1: 240
hidden_dim_2: 195
learning_rate: 0.01
learning_rate_scheduler: 1
loss: 1.223861755784025
max_grad_norm: 1.0
max_text_len: 75
model: bow
n_blocks: 500
n_blocks_test: 200
n_epochs: 15
n_trainable_parameters: 1111
n_workers: 6
noise: 2.7565545654296875
non_dp_batch_size: 256
per_layer_clipping: 0
rdp_epsilons:
- 0.003878918133040088
- 0.0045258126738190185
- 0.0051728239088993785
- 0.0064671967280191655
- 0.007762036975518741
- 0.010353121186908494
- 0.012946079353993127
- 0.015540914294639328
- 0.02073622580224798
- 0.04159311110455767
- 0.08367476730930011
- 0.16935265544364453
target_epsilon: 0.5
task: product
test_size: 39077
timeframe_days: 0
total_time: 47.15247201919556
train_size: 165215
training_accuracy_epochs:
- 0.45728480914066283
- 0.5337486859466055
- 0.5475563492093768
- 0.5573296992502776
- 0.5653376591763473
- 0.5698815701630315
- 0.5724902219079399
- 0.5752930084766426
- 0.577931994728267
- 0.5800189170344122
- 0.5813960447687233
- 0.5830401025822597
- 0.5840289641190045
- 0.5858550218525779
- 0.5865162853243315
training_loss_epochs:
- 1.7437380860591758
- 1.5428696051606992
- 1.4743306921620674
- 1.4311314228133027
- 1.4008519223758154
- 1.3765345206988857
- 1.3590485013177243
- 1.345546485461625
- 1.333235815240832
- 1.322169913153343
- 1.311588490537822
- 1.3026193811975677
- 1.294603222696652
- 1.285593905766022
- 1.2797800751742472
training_time: 22.5407977104187
user_level: 0
validation_accuracy_epochs:
- 0.5410640700296923
- 0.56052263397159
- 0.57454140439178
- 0.582527675411918
- 0.5835155320890022
- 0.5899387887029937
- 0.5980479879812761
- 0.5981094602382544
- 0.5962083773179487
- 0.5978987090515367
- 0.6018632993553624
- 0.6025350437019811
- 0.6040980581081274
- 0.6013452338449883
- 0.6028335979490569
validation_loss_epochs:
- 1.5530512477412368
- 1.4537057190230398
- 1.394802779862375
- 1.3473862698583892
- 1.327085473320701
- 1.3101909630226367
- 1.2807634707653162
- 1.2652443358392427
- 1.2692964763352366
- 1.249989238652316
- 1.2367714209990068
- 1.2243929848526462
- 1.2248888991095803
- 1.226789091572617
- 1.2126929904475356
virtual_batch_multiplier: 0
vocab_size: 10000
