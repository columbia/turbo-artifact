accuracy: 0.7786939260885888
adaptive_batch_size: 1
alphas:
- 1.5
- 1.75
- 2
- 2.5
- 3
- 4
- 5
- 6
- 8
- 16
- 32
- 64
batch_size: 406
best_alpha: 32.0
delta: 1.0e-09
device: cuda
dp: 1
dp_eval: 0
dropout: 0.25
dynamic_clipping: 0
embedding_dim: 100
epsilon: 0.9905773659710048
hidden_dim: 40
hidden_dim_1: 240
hidden_dim_2: 195
learning_rate: 0.01
learning_rate_scheduler: 1
loss: 0.6563713433816261
max_grad_norm: 1.0
max_text_len: 50
model: lstm
n_blocks: 500
n_blocks_test: 200
n_epochs: 15
n_trainable_parameters: 22761
n_workers: 6
noise: 1.642674102783203
non_dp_batch_size: 256
per_layer_clipping: 0
rdp_epsilons:
- 0.012365452649447661
- 0.014430909619989052
- 0.016497671029719958
- 0.02063511462087298
- 0.024777798424544775
- 0.033078946955730874
- 0.041401238066290064
- 0.04974479444774085
- 0.06649620015387098
- 0.13437787519970515
- 0.32208491961789476
- 35047.64531257814
target_epsilon: 1.0
task: sentiment
test_size: 39077
timeframe_days: 0
total_time: 412.02893233299255
train_size: 165215
training_accuracy_epochs:
- 0.6586728501202438
- 0.6951394007710988
- 0.7508189835278272
- 0.7651241092846311
- 0.7679693624010226
- 0.7669319677822696
- 0.7860236697889901
- 0.7841369478866972
- 0.7835484828267779
- 0.7806000960577885
- 0.7862117366837751
- 0.784531278416441
- 0.7851136759877793
- 0.7872187959149554
- 0.7896939831707865
training_loss_epochs:
- 0.6975679766074777
- 0.7228812547446472
- 0.6728806275452299
- 0.6539912493945342
- 0.6573737861194047
- 0.6606262219069626
- 0.6263851396409161
- 0.6301063393137137
- 0.6295265981863285
- 0.6388682982164063
- 0.6297316794912217
- 0.6432769049711415
- 0.6337031748494492
- 0.6293255568578325
- 0.62374783355027
training_time: 385.2312707901001
user_level: 0
validation_accuracy_epochs:
- 0.6523932344985731
- 0.7050788872169725
- 0.7270970922527891
- 0.7399128801894911
- 0.737840580217766
- 0.762392091028618
- 0.7630594390811343
- 0.7733463121182991
- 0.776402083310214
- 0.7680645801804282
- 0.7682006882898735
- 0.7680601874987284
- 0.7699261416088451
- 0.7723891969883081
- 0.7724023587775953
validation_loss_epochs:
- 0.7405569625623298
- 0.7099571426709493
- 0.6888033910231157
- 0.7366790943073503
- 0.7284614172848788
- 0.6684259248502327
- 0.7027403603900563
- 0.6506220021031119
- 0.6112969680265947
- 0.6591208649404121
- 0.6837598555015795
- 0.6640892353924838
- 0.6755409023978494
- 0.6548133691151937
- 0.6682688359058264
virtual_batch_multiplier: 0
vocab_size: 10000
