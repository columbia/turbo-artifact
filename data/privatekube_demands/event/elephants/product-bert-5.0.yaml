accuracy: 0.7208541475499941
adaptive_batch_size: 1
alphas:
- 1.5
- 1.75
- 2
- 2.5
- 3
- 4
- 5
- 6
- 8
- 16
- 32
- 64
batch_size: 64
best_alpha: 6.0
delta: 1.0e-09
device: cuda
dp: 1
dp_eval: 0
dropout: 0.25
dynamic_clipping: 0
embedding_dim: 100
epsilon: 4.964306824449803
hidden_dim: 100
hidden_dim_1: 240
hidden_dim_2: 195
learning_rate: 0.0005
learning_rate_scheduler: 1
loss: 1.0205814386583218
max_grad_norm: 1.0
max_text_len: 140
model: bert
n_blocks: 500
n_blocks_test: 200
n_epochs: 3
n_trainable_parameters: 858379
n_workers: 6
noise: 0.7033142948150635
non_dp_batch_size: 256
per_layer_clipping: 0
rdp_epsilons:
- 0.033319763169863695
- 0.03925365338742219
- 0.0453206574005448
- 0.05791091356883591
- 0.0712463420301605
- 0.10159619744426923
- 0.15078960489562443
- 0.8196536570605211
- 1493.139327643486
- 12623.651688824693
- 33952.974715149925
- 76197.06498990163
target_epsilon: 5.0
task: product
test_size: 39786
timeframe_days: 0
total_time: 804.1759276390076
train_size: 166581
training_accuracy_epochs:
- 0.551012442352037
- 0.6631017006149116
- 0.6829301979246734
training_loss_epochs:
- 1.4202198191480762
- 1.175574300130636
- 1.1351586819084492
training_time: 773.2097713947296
user_level: 0
validation_accuracy_epochs:
- 0.6690418958090819
- 0.7014186986936972
- 0.717279790685727
validation_loss_epochs:
- 1.1154417200730398
- 1.0519642976041024
- 1.0161477728531911
virtual_batch_multiplier: 6
vocab_size: 10000
