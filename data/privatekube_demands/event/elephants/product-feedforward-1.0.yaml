accuracy: 0.621715731822051
adaptive_batch_size: 1
alphas:
- 1.5
- 1.75
- 2
- 2.5
- 3
- 4
- 5
- 6
- 8
- 16
- 32
- 64
batch_size: 254
best_alpha: 32.0
delta: 1.0e-09
device: cuda
dp: 1
dp_eval: 0
dropout: 0.25
dynamic_clipping: 0
embedding_dim: 100
epsilon: 0.9920475714879368
hidden_dim: 100
hidden_dim_1: 185
hidden_dim_2: 150
learning_rate: 0.01
learning_rate_scheduler: 1
loss: 1.4559789284483178
max_grad_norm: 1.0
max_text_len: 60
model: feedforward
n_blocks: 200
n_blocks_test: 200
n_epochs: 15
n_trainable_parameters: 48246
n_workers: 6
noise: 1.8715536499023435
non_dp_batch_size: 256
per_layer_clipping: 0
rdp_epsilons:
- 0.014493339607875567
- 0.01691492246137224
- 0.019338234263818227
- 0.024190055491501994
- 0.029048825018887562
- 0.03878729627063078
- 0.04855382391067626
- 0.05834858573162823
- 0.07802353278004158
- 0.15788962226749753
- 0.32355512513482676
- 13402.763099975355
target_epsilon: 1.0
task: product
test_size: 39077
timeframe_days: 0
total_time: 45.45893859863281
train_size: 64934
training_accuracy_epochs:
- 0.47471050878658017
- 0.5567237864522373
- 0.5670989644293691
- 0.5733981770627639
- 0.5754361562869128
- 0.5794966821577034
- 0.5892388479382384
- 0.5923730144313738
- 0.5949822474928463
- 0.598100973811804
- 0.6004477416767794
- 0.6007256475149416
- 0.6009572351680083
- 0.6012351428761201
- 0.6013123369684407
training_loss_epochs:
- 1.6923654406678443
- 1.527229207169776
- 1.5343197406507005
- 1.552017427893246
- 1.593577355964511
- 1.6621264420303643
- 1.607461110750834
- 1.577319228882883
- 1.556765145414016
- 1.5403838036107083
- 1.5251145741518806
- 1.52267874175427
- 1.522528343107186
- 1.5203777776044958
- 1.5208834951999142
training_time: 21.919636011123657
user_level: 0
validation_accuracy_epochs:
- 0.5678418760116284
- 0.5833270274675809
- 0.5945008099079132
- 0.6043748763891367
- 0.5974220186471939
- 0.6105159337703998
- 0.6157484547449992
- 0.6184299072394004
- 0.6216897173569753
- 0.6243080783348817
- 0.625515260375463
- 0.6244426770852163
- 0.6254668877674983
- 0.6253638370678976
- 0.6257823533736743
validation_loss_epochs:
- 1.4747895758885603
- 1.4071270525455475
- 1.4823948809733758
- 1.4475402671557207
- 1.6049628807948186
- 1.5498737119711363
- 1.5177104266790242
- 1.476928832439276
- 1.4426870048046112
- 1.4377106703244722
- 1.4352678564878611
- 1.439511156999148
- 1.4395862771914556
- 1.4275015615499937
- 1.429931979912978
virtual_batch_multiplier: 0
vocab_size: 10000
