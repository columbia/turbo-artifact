accuracy: 0.8242528422277456
adaptive_batch_size: 1
alphas:
- 1.5
- 1.75
- 2
- 2.5
- 3
- 4
- 5
- 6
- 8
- 16
- 32
- 64
batch_size: 64
best_alpha: 32.0
delta: 1.0e-09
device: cuda
dp: 1
dp_eval: 0
dropout: 0.25
dynamic_clipping: 0
embedding_dim: 100
epsilon: 0.9940509662014363
hidden_dim: 100
hidden_dim_1: 240
hidden_dim_2: 195
learning_rate: 0.0005
learning_rate_scheduler: 1
loss: 0.7012916442330244
max_grad_norm: 1.0
max_text_len: 140
model: bert
n_blocks: 500
n_blocks_test: 200
n_epochs: 3
n_trainable_parameters: 855809
n_workers: 6
noise: 1.6191901075839994
non_dp_batch_size: 256
per_layer_clipping: 0
rdp_epsilons:
- 0.00240809816388321
- 0.0028103120541231874
- 0.003212773757942221
- 0.004018442049438765
- 0.004825105845095839
- 0.006441431178141472
- 0.008061772368277835
- 0.009686152255689407
- 0.012947120650442737
- 0.02615727575170309
- 0.32555851984832623
- 7859.495969369826
target_epsilon: 1.0
task: sentiment
test_size: 39786
timeframe_days: 0
total_time: 802.5094802379608
train_size: 166581
training_accuracy_epochs:
- 0.6598109627209838
- 0.7525341083781706
- 0.8096296118370484
training_loss_epochs:
- 1.0437703028401442
- 0.7593454229577425
- 0.7133847280168515
training_time: 772.1563906669617
user_level: 0
validation_accuracy_epochs:
- 0.6634615384615384
- 0.8141848387626501
- 0.8201193339549578
validation_loss_epochs:
- 0.9281063710267727
- 0.6932165373403293
- 0.7009974921910236
virtual_batch_multiplier: 6
vocab_size: 10000
