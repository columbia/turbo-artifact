accuracy: 0.8220266804242824
adaptive_batch_size: 1
alphas:
- 1.5
- 1.75
- 2
- 2.5
- 3
- 4
- 5
- 6
- 8
- 16
- 32
- 64
batch_size: 64
best_alpha: 6.0
delta: 1.0e-09
device: cuda
dp: 1
dp_eval: 0
dropout: 0.25
dynamic_clipping: 0
embedding_dim: 100
epsilon: 4.982840986690321
hidden_dim: 100
hidden_dim_1: 240
hidden_dim_2: 195
learning_rate: 0.0005
learning_rate_scheduler: 1
loss: 0.7025506178282465
max_grad_norm: 1.0
max_text_len: 140
model: bert
n_blocks: 200
n_blocks_test: 200
n_epochs: 3
n_trainable_parameters: 855809
n_workers: 6
noise: 0.7185729312896727
non_dp_batch_size: 256
per_layer_clipping: 0
rdp_epsilons:
- 0.03855835925353187
- 0.0454613945649976
- 0.052531799037466964
- 0.06724731927801433
- 0.08290280916873317
- 0.11882950776348637
- 0.17701145668298598
- 0.8381878193010387
- 1107.583617739477
- 9436.849014681184
- 25397.56374823942
- 57008.33294319735
target_epsilon: 5.0
task: sentiment
test_size: 39786
timeframe_days: 0
total_time: 337.8356087207794
train_size: 65085
training_accuracy_epochs:
- 0.6599563238188977
- 0.728761687992126
- 0.8082400344488189
training_loss_epochs:
- 1.0486377363833856
- 0.803521417257354
- 0.7148570984337977
training_time: 307.9737112522125
user_level: 0
validation_accuracy_epochs:
- 0.659791380740129
- 0.8094844611791464
- 0.8204842035013896
validation_loss_epochs:
- 0.9847347759283506
- 0.6660666298121214
- 0.6959153439563054
virtual_batch_multiplier: 3
vocab_size: 10000
