accuracy: 0.7096252488361677
adaptive_batch_size: 1
alphas:
- 1.5
- 1.75
- 2
- 2.5
- 3
- 4
- 5
- 6
- 8
- 16
- 32
- 64
batch_size: 64
best_alpha: 32.0
delta: 1.0e-09
device: cuda
dp: 1
dp_eval: 0
dropout: 0.25
dynamic_clipping: 0
embedding_dim: 100
epsilon: 0.9979506603190105
hidden_dim: 100
hidden_dim_1: 240
hidden_dim_2: 195
learning_rate: 0.0005
learning_rate_scheduler: 1
loss: 1.0442628500162596
max_grad_norm: 1.0
max_text_len: 140
model: bert
n_blocks: 1000
n_blocks_test: 200
n_epochs: 3
n_trainable_parameters: 858379
n_workers: 6
noise: 1.580924308300018
non_dp_batch_size: 256
per_layer_clipping: 0
rdp_epsilons:
- 0.0018978930110051806
- 0.0022147498366393847
- 0.0025317617915577156
- 0.0031662517992817342
- 0.003801364419557492
- 0.005073463129651298
- 0.006348069231053772
- 0.0076251941254178645
- 0.010187046369364527
- 0.02053755367440791
- 0.3294582139659005
- 11096.036231349672
target_epsilon: 1.0
task: product
test_size: 39786
timeframe_days: 0
total_time: 1413.441811800003
train_size: 298746
training_accuracy_epochs:
- 0.5635546121705592
- 0.6617641150632098
- 0.6813832494107563
training_loss_epochs:
- 1.3895100473157083
- 1.1630254266270739
- 1.136333898326072
training_time: 1381.7766218185425
user_level: 0
validation_accuracy_epochs:
- 0.6542539493395731
- 0.6968470983780347
- 0.7087053573475435
validation_loss_epochs:
- 1.1377569227837598
- 1.066215405957057
- 1.0306885623588011
virtual_batch_multiplier: 8
vocab_size: 10000
