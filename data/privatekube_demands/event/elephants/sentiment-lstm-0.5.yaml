accuracy: 0.7723098190294372
adaptive_batch_size: 1
alphas:
- 1.5
- 1.75
- 2
- 2.5
- 3
- 4
- 5
- 6
- 8
- 16
- 32
- 64
batch_size: 545
best_alpha: 64.0
delta: 1.0e-09
device: cuda
dp: 1
dp_eval: 0
dropout: 0.25
dynamic_clipping: 0
embedding_dim: 100
epsilon: 0.49589935464933044
hidden_dim: 40
hidden_dim_1: 240
hidden_dim_2: 195
learning_rate: 0.01
learning_rate_scheduler: 1
loss: 0.6492125549250178
max_grad_norm: 1.0
max_text_len: 50
model: lstm
n_blocks: 1000
n_blocks_test: 200
n_epochs: 15
n_trainable_parameters: 22761
n_workers: 6
noise: 2.4208645629882812
non_dp_batch_size: 256
per_layer_clipping: 0
rdp_epsilons:
- 0.003824084223680302
- 0.004461833808022675
- 0.005099698393287823
- 0.006375772859009793
- 0.0076523079602036905
- 0.010206761503454407
- 0.012763061828367181
- 0.015321211747341686
- 0.02044307165222762
- 0.0410050623963281
- 0.08249170052570408
- 0.1669586270787525
target_epsilon: 0.5
task: sentiment
test_size: 39077
timeframe_days: 0
total_time: 531.0287480354309
train_size: 297910
training_accuracy_epochs:
- 0.6825822564490113
- 0.7617669842400394
- 0.7783378755653297
- 0.7878381605550047
- 0.787367684282226
- 0.7889572254249028
- 0.7828376580288995
- 0.7777699408950386
- 0.7813354897630084
- 0.7838693467470316
- 0.7864166459976099
- 0.7817185920673412
- 0.7850757854762095
- 0.7891958241279309
- 0.7858856796344995
training_loss_epochs:
- 0.7148450364123334
- 0.6852533781812304
- 0.651675011976298
- 0.6294098147651651
- 0.6334334124466439
- 0.6289532331974952
- 0.6356742240133739
- 0.6444361673824953
- 0.6311601274288617
- 0.6255126286011475
- 0.6162859713419889
- 0.6233431916861307
- 0.6013291720505599
- 0.5993959435940662
- 0.6090440670430879
training_time: 503.89234709739685
user_level: 0
validation_accuracy_epochs:
- 0.7367517501115799
- 0.7583442404866219
- 0.7673312351107597
- 0.7740758806467056
- 0.7117097079753876
- 0.7691408743460973
- 0.766158439218998
- 0.7724351833264033
- 0.7666599750518799
- 0.7767333512504896
- 0.7795040160417557
- 0.7727670023838679
- 0.7661500374476115
- 0.783656895160675
- 0.7686561619242033
validation_loss_epochs:
- 0.6901970505714417
- 0.6796087274948756
- 0.6648950204253197
- 0.5987120320399603
- 0.8062478477756182
- 0.6387797817587852
- 0.7105661953488985
- 0.6590259994069735
- 0.679129938284556
- 0.6069841881593069
- 0.6419949581225713
- 0.6272867446144422
- 0.6105426450570425
- 0.6175238663951556
- 0.6597312341133753
virtual_batch_multiplier: 0
vocab_size: 10000
