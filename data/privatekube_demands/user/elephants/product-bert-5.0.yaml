accuracy: 0.7173121459422771
adaptive_batch_size: 1
alphas:
- 1.5
- 1.75
- 2
- 2.5
- 3
- 4
- 5
- 6
- 8
- 16
- 32
- 64
batch_size: 64
best_alpha: 6.0
delta: 1.0e-09
device: cuda
dp: 1
dp_eval: 0
dropout: 0.25
dynamic_clipping: 0
embedding_dim: 100
epsilon: 4.955206708176471
hidden_dim: 100
hidden_dim_1: 240
hidden_dim_2: 195
learning_rate: 0.0005
learning_rate_scheduler: 1
loss: 1.0866109447080605
max_grad_norm: 1.0
max_text_len: 140
model: bert
n_blocks: 5000
n_blocks_test: 200
n_epochs: 5
n_train_users: 104910
n_trainable_parameters: 858379
n_workers: 6
noise: 0.7309705734252929
non_dp_batch_size: 256
per_layer_clipping: 0
rdp_epsilons:
- 0.06167524281953874
- 0.07266212441300547
- 0.08389372424620697
- 0.10718728746427438
- 0.13181192274164774
- 0.18721606999699025
- 0.2672166801411651
- 0.8105535407871887
- 1422.2753777709577
- 14421.58862988325
- 39303.12902544741
- 88568.11687605269
target_epsilon: 5.0
task: product
test_size: 39786
timeframe_days: 0
total_time: 864.8273591995239
train_size: 1348622
training_accuracy_epochs:
- 0.5614227425259305
- 0.6733717205613179
- 0.7029152684563759
- 0.7180350061012812
- 0.7269199969493594
training_loss_epochs:
- 1.4034300852360124
- 1.1224423730206097
- 1.070345968062591
- 1.0530082480146654
- 1.0320701524387996
training_time: 816.950896024704
user_level: 1
validation_accuracy_epochs:
- 0.6316642342851713
- 0.6774875515928636
- 0.6983387708090819
- 0.7111413977467097
- 0.7172046704934194
validation_loss_epochs:
- 1.21982115564438
- 1.1305303367284627
- 1.117695328564598
- 1.079988884094816
- 1.0770975874307065
virtual_batch_multiplier: 5
vocab_size: 10000
