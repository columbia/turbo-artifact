accuracy: 0.712762928756487
adaptive_batch_size: 1
alphas:
- 1.5
- 1.75
- 2
- 2.5
- 3
- 4
- 5
- 6
- 8
- 16
- 32
- 64
batch_size: 64
best_alpha: 32.0
delta: 1.0e-09
device: cuda
dp: 1
dp_eval: 0
dropout: 0.25
dynamic_clipping: 0
embedding_dim: 100
epsilon: 0.9997608547838283
hidden_dim: 100
hidden_dim_1: 240
hidden_dim_2: 195
learning_rate: 0.0005
learning_rate_scheduler: 1
loss: 1.0926280504637593
max_grad_norm: 1.0
max_text_len: 140
model: bert
n_blocks: 10000
n_blocks_test: 200
n_epochs: 5
n_train_users: 183753
n_trainable_parameters: 858379
n_workers: 6
noise: 1.6088190031051637
non_dp_batch_size: 256
per_layer_clipping: 0
rdp_epsilons:
- 0.003697365781896167
- 0.004314818050967044
- 0.00493262142304076
- 0.00616928332791936
- 0.007407355136385869
- 0.009887743192998504
- 0.012373815190494021
- 0.014865601004210928
- 0.01986643499553314
- 0.040104498836439316
- 0.33126840843071825
- 14596.761381224807
target_epsilon: 1.0
task: product
test_size: 39786
timeframe_days: 0
total_time: 1488.7036080360413
train_size: 2570313
training_accuracy_epochs:
- 0.5663586293974225
- 0.6727729885057471
- 0.7011167711598746
- 0.7181458986415883
- 0.7248345524207593
training_loss_epochs:
- 1.4038128702742678
- 1.1076537538326314
- 1.0584743822629923
- 1.0349380029738469
- 1.0257453445419125
training_time: 1421.878273487091
user_level: 1
validation_accuracy_epochs:
- 0.6275218922931415
- 0.671381353185727
- 0.6940783826777568
- 0.7070956390637618
- 0.7115169987082481
validation_loss_epochs:
- 1.2134439523976583
- 1.1293559623165772
- 1.1055236048996449
- 1.0702465016108293
- 1.0894810270804625
virtual_batch_multiplier: 6
vocab_size: 10000
