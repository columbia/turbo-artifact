accuracy: 0.8262900015357223
adaptive_batch_size: 1
alphas:
- 1.5
- 1.75
- 2
- 2.5
- 3
- 4
- 5
- 6
- 8
- 16
- 32
- 64
batch_size: 64
best_alpha: 32.0
delta: 1.0e-09
device: cuda
dp: 1
dp_eval: 0
dropout: 0.25
dynamic_clipping: 0
embedding_dim: 100
epsilon: 0.9963060003838943
hidden_dim: 100
hidden_dim_1: 240
hidden_dim_2: 195
learning_rate: 0.0005
learning_rate_scheduler: 1
loss: 0.7191275596091602
max_grad_norm: 1.0
max_text_len: 140
model: bert
n_blocks: 5000
n_blocks_test: 200
n_epochs: 5
n_train_users: 104910
n_trainable_parameters: 855809
n_workers: 6
noise: 1.6612705659866331
non_dp_batch_size: 256
per_layer_clipping: 0
rdp_epsilons:
- 0.00499361553828863
- 0.005828094129280241
- 0.006663206825985962
- 0.008335338921862482
- 0.010010020570248104
- 0.013367067739237367
- 0.016734419301977426
- 0.020112147100152484
- 0.026899023234990032
- 0.0544765826271806
- 0.32781355403078427
- 9365.182974043093
target_epsilon: 1.0
task: sentiment
test_size: 39786
timeframe_days: 0
total_time: 867.3516428470612
train_size: 1348622
training_accuracy_epochs:
- 0.6497197223917023
- 0.7083206223306895
- 0.7898585265405735
- 0.8101929530201343
- 0.8170187614399024
training_loss_epochs:
- 1.0584027760999097
- 0.8457895323152292
- 0.734250373170098
- 0.7184416192962747
- 0.7072363362998189
training_time: 819.4493415355682
user_level: 1
validation_accuracy_epochs:
- 0.6598665009324367
- 0.7730297047931415
- 0.8165135647241886
- 0.8213427198620943
- 0.8242831390637618
validation_loss_epochs:
- 0.9613803728268697
- 0.6959615203623588
- 0.7247011501055497
- 0.7142795857328635
- 0.7157775328422968
virtual_batch_multiplier: 5
vocab_size: 10000
