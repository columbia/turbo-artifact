accuracy: 0.7406491636271645
adaptive_batch_size: 1
alphas:
- 1.5
- 1.75
- 2
- 2.5
- 3
- 4
- 5
- 6
- 8
- 16
- 32
- 64
batch_size: 64
best_alpha: 64.0
delta: 1.0e-09
device: cuda
dp: 1
dp_eval: 0
dropout: 0.25
dynamic_clipping: 0
embedding_dim: 100
epsilon: 0.49653555739001515
hidden_dim: 100
hidden_dim_1: 240
hidden_dim_2: 195
learning_rate: 0.0005
learning_rate_scheduler: 1
loss: 1.0194569610514441
max_grad_norm: 1.0
max_text_len: 140
model: bert
n_blocks: 50000
n_blocks_test: 200
n_epochs: 5
n_train_users: 884427
n_trainable_parameters: 858379
n_workers: 6
noise: 2.153361592292786
non_dp_batch_size: 256
per_layer_clipping: 0
rdp_epsilons:
- 0.0009150820220424759
- 0.0010676658777830285
- 0.0012202698231940407
- 0.0015255379405958308
- 0.0018308863907939997
- 0.0024418245444167803
- 0.0030530846464334187
- 0.0036646670598622895
- 0.00488880027653131
- 0.009798298679895167
- 0.019680146843207468
- 0.16759482981943719
target_epsilon: 0.5
task: product
test_size: 39786
timeframe_days: 0
total_time: 6983.381135225296
train_size: 12951426
training_accuracy_epochs:
- 0.6525639518054852
- 0.7265822870685288
- 0.7371678033866416
- 0.7431796801505174
- 0.7473711466097402
training_loss_epochs:
- 1.1849522918486477
- 1.024726685773568
- 1.0061862431539366
- 0.9926929261406817
- 0.9867890658476685
training_time: 6788.573826313019
user_level: 1
validation_accuracy_epochs:
- 0.7035542583236327
- 0.723203554462928
- 0.7314560442016675
- 0.737851991962928
- 0.742734804462928
validation_loss_epochs:
- 1.0940816789292371
- 1.0391991387766142
- 1.032145649767839
- 1.03123470954597
- 1.0133700373654182
virtual_batch_multiplier: 14
vocab_size: 10000
