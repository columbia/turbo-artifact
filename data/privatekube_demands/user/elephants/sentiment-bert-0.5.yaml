accuracy: 0.8203328357248828
adaptive_batch_size: 1
alphas:
- 1.5
- 1.75
- 2
- 2.5
- 3
- 4
- 5
- 6
- 8
- 16
- 32
- 64
batch_size: 64
best_alpha: 64.0
delta: 1.0e-09
device: cuda
dp: 1
dp_eval: 0
dropout: 0.25
dynamic_clipping: 0
embedding_dim: 100
epsilon: 0.49635656704170206
hidden_dim: 100
hidden_dim_1: 240
hidden_dim_2: 195
learning_rate: 0.0005
learning_rate_scheduler: 1
loss: 0.7268019598875781
max_grad_norm: 1.0
max_text_len: 140
model: bert
n_blocks: 5000
n_blocks_test: 200
n_epochs: 5
n_train_users: 104910
n_trainable_parameters: 855809
n_workers: 6
noise: 2.3517238664627076
non_dp_batch_size: 256
per_layer_clipping: 0
rdp_epsilons:
- 0.002267321678459666
- 0.002645633035172068
- 0.003024065900086886
- 0.003781296395710707
- 0.004539013818265592
- 0.006055912084420782
- 0.007574766004844129
- 0.009095580909596272
- 0.012143115112048623
- 0.024412774008646346
- 0.049343122335940084
- 0.16741583947112412
target_epsilon: 0.5
task: sentiment
test_size: 39786
timeframe_days: 0
total_time: 867.2343757152557
train_size: 1348622
training_accuracy_epochs:
- 0.6494813910921293
- 0.6658690512507627
- 0.7493422056131788
- 0.7927566351433801
- 0.8076952410006101
training_loss_epochs:
- 1.062076757163664
- 0.9530408620070655
- 0.75336450520196
- 0.7325283964917455
- 0.7192233212205824
training_time: 819.7833805084229
user_level: 1
validation_accuracy_epochs:
- 0.6600596669774789
- 0.7232572115384616
- 0.7902536919483771
- 0.8124356115093598
- 0.8168140454934194
validation_loss_epochs:
- 1.0158193228909602
- 0.7575885113328695
- 0.6945548958789843
- 0.7198497834973611
- 0.7197008858291576
virtual_batch_multiplier: 5
vocab_size: 10000
