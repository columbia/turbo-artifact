accuracy: 0.8132631871669622
adaptive_batch_size: 1
alphas:
- 1.5
- 1.75
- 2
- 2.5
- 3
- 4
- 5
- 6
- 8
- 16
- 32
- 64
batch_size: 64
best_alpha: 6.0
delta: 1.0e-09
device: cuda
dp: 1
dp_eval: 0
dropout: 0.25
dynamic_clipping: 0
embedding_dim: 100
epsilon: 4.990854353187249
hidden_dim: 100
hidden_dim_1: 240
hidden_dim_2: 195
learning_rate: 0.0005
learning_rate_scheduler: 1
loss: 0.707371194550462
max_grad_norm: 1.0
max_text_len: 140
model: bert
n_blocks: 500
n_blocks_test: 200
n_epochs: 5
n_train_users: 25645
n_trainable_parameters: 855809
n_workers: 6
noise: 0.7691171646118165
non_dp_batch_size: 256
per_layer_clipping: 0
rdp_epsilons:
- 0.0807479939372011
- 0.0952697449871299
- 0.11016096740554818
- 0.14119828000842105
- 0.17424416528278128
- 0.2494360583057199
- 0.3564394723251379
- 0.8462011857979672
- 707.4811263653465
- 7870.582438168341
- 21576.94487560933
- 48711.77546874599
target_epsilon: 5.0
task: sentiment
test_size: 39786
timeframe_days: 0
total_time: 241.70425081253052
train_size: 166581
training_accuracy_epochs:
- 0.6474609375
- 0.6538671875
- 0.6675390625
- 0.7373046875
- 0.782265625
training_loss_epochs:
- 1.045924987345934
- 1.0676514802128076
- 0.9476349699497223
- 0.7702238267660141
- 0.7317670234665274
training_time: 210.37211084365845
user_level: 1
validation_accuracy_epochs:
- 0.6603279535013896
- 0.6589865214549578
- 0.7245771807546799
- 0.775905735217608
- 0.8111371054099157
validation_loss_epochs:
- 1.1101459749042988
- 1.046496396454481
- 0.7312212908783784
- 0.697162544569717
- 0.7091696177107784
virtual_batch_multiplier: 2
vocab_size: 10000
