{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload \n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from privacypacking.utils.utils import load_logs, global_metrics\n",
    "import pandas as pd\n",
    "from experiments.ray.analysis import load_tasks, load_ray_experiment, load_latest_ray_experiment, load_latest_scheduling_results, load_latest_scheduling_results, load_latest_ray_experiment, load_scheduling_queue\n",
    "import plotly.express as px\n",
    "from privacypacking.budget.curves import  LaplaceCurve, GaussianCurve, SubsampledGaussianCurve\n",
    "from privacypacking.budget import Budget, Task, Block\n",
    "from privacypacking.schedulers.metrics import OverflowRelevance, FlatRelevance\n",
    "from privacypacking.budget.block_selection import RandomBlocks\n",
    "from privacypacking.utils.plot import plot_budgets\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from omegaconf import OmegaConf\n",
    "from pathlib import Path\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "block = Budget.from_epsilon_delta(epsilon=10, delta=1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_task_dir(path: str) -> pd.DataFrame:\n",
    "    dict_list = defaultdict(list)\n",
    "    for curve_file in Path(path).glob(\"*.yaml\"):\n",
    "        d = OmegaConf.load(curve_file)\n",
    "        for alpha, epsilon in zip(d[\"alphas\"], d[\"rdp_epsilons\"]):\n",
    "            if block.epsilon(alpha) > 0:\n",
    "                dict_list[\"alphas\"].append(alpha)\n",
    "                dict_list[\"rdp_epsilons\"].append(epsilon)\n",
    "                dict_list[\"normalized_epsilons\"].append(epsilon / block.epsilon(alpha))\n",
    "                dict_list[\"task\"].append(curve_file.name)\n",
    "    return pd.DataFrame(dict_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigma_range(min=0.01, max=100) -> pd.DataFrame:\n",
    "    dict_list = defaultdict(list)\n",
    "    for sigma in np.geomspace(min, max, 30):\n",
    "        # gaussian = GaussianCurve(sigma=sigma)\n",
    "        curve = LaplaceCurve(laplace_noise=sigma)\n",
    "        # d = OmegaConf.load(curve_file)\n",
    "        for alpha, epsilon in zip(curve.alphas, curve.epsilons):\n",
    "            if block.epsilon(alpha) > 0:\n",
    "                dict_list[\"alphas\"].append(alpha)\n",
    "                dict_list[\"rdp_epsilons\"].append(epsilon)\n",
    "                dict_list[\"normalized_epsilons\"].append(epsilon / block.epsilon(alpha))\n",
    "                dict_list[\"task\"].append(sigma)\n",
    "    return pd.DataFrame(dict_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autodp.mechanism_zoo import ExponentialMechanism, RandresponseMechanism, GaussianSVT_Mechanism\n",
    "from privacypacking.budget.utils import ALPHAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = ExponentialMechanism(eps=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autodp_range(min=0.1, max=100, mechanism=GaussianSVT_Mechanism) -> pd.DataFrame:\n",
    "    dict_list = defaultdict(list)\n",
    "    for eps in np.geomspace(min, max, 10):\n",
    "        for k in np.arange(1,100, step=10):\n",
    "            # gaussian = GaussianCurve(sigma=sigma)\n",
    "            # curve = mechanism(eps=eps)\n",
    "            # curve=mechanism(p=eps)\n",
    "            curve=mechanism(params={\"sigma\": eps, \"k\": k, \"c\": 100}, rdp_c_1=False)\n",
    "            # d = OmegaConf.load(curve_file)\n",
    "            # for alpha, epsilon in zip(curve.alphas, curve.epsilons):\n",
    "            for alpha in ALPHAS:\n",
    "                epsilon = curve.get_RDP(alpha)\n",
    "                if block.epsilon(alpha) > 0:\n",
    "                    dict_list[\"alphas\"].append(alpha)\n",
    "                    dict_list[\"rdp_epsilons\"].append(epsilon)\n",
    "                    dict_list[\"normalized_epsilons\"].append(epsilon / block.epsilon(alpha))\n",
    "                    dict_list[\"task\"].append((eps,k))\n",
    "    return pd.DataFrame(dict_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subsampled_range(min=0.01, max=100) -> pd.DataFrame:\n",
    "    dict_list = defaultdict(list)\n",
    "    for sigma in np.geomspace(min, max, 10):\n",
    "        for sampling in np.geomspace(1e-8, 1, 10):\n",
    "            # gaussian = GaussianCurve(sigma=sigma)\n",
    "            curve = SubsampledGaussianCurve(sigma=sigma, sampling_probability=sampling, steps=1)\n",
    "            # d = OmegaConf.load(curve_file)\n",
    "            for alpha, epsilon in zip(curve.alphas, curve.epsilons):\n",
    "                if block.epsilon(alpha) > 0:\n",
    "                    dict_list[\"alphas\"].append(alpha)\n",
    "                    dict_list[\"rdp_epsilons\"].append(epsilon)\n",
    "                    dict_list[\"normalized_epsilons\"].append(epsilon / block.epsilon(alpha))\n",
    "                    dict_list[\"task\"].append((sigma, sampling))\n",
    "    return pd.DataFrame(dict_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = load_task_dir(\"/home/pierre/privacypacking/data/mixed_curves/tasks\")\n",
    "# df = load_task_dir(\"/home/pierre/privacypacking/data/privatekube_event_g0.0_l0.5_p=grid/tasks\")\n",
    "# df = sigma_range()\n",
    "# df = subsampled_range()\n",
    "df = autodp_range()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.groupby(\"task\").agg({\"normalized_epsilons\": \"min\", \"alphas\": \"first\"})\n",
    "indx = df.groupby('task')['normalized_epsilons'].idxmin()\n",
    "best_alpha = df.loc[indx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line(\n",
    "    df,\n",
    "    x=\"alphas\",\n",
    "    y=\"normalized_epsilons\",\n",
    "    color=\"task\",\n",
    "    log_y=True,\n",
    "    log_x=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(\n",
    "    best_alpha,\n",
    "    x=\"alphas\",\n",
    "    y=\"normalized_epsilons\",\n",
    "    color=\"task\",\n",
    "    log_y=True,\n",
    "    log_x=True,\n",
    "    title=\"Epsilon for the best alpha of each task\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curve_zoo = []\n",
    "for sigma in np.geomspace(0.01, 10, 100):\n",
    "# for sigma in np.linspace(0.01, 100, 100):\n",
    "\n",
    "    gaussian = GaussianCurve(sigma=sigma)\n",
    "for sigma in np.geomspace(0.01, 10, 100):\n",
    "    curve_zoo.append(LaplaceCurve(laplace_noise=sigma))\n",
    "for sigma in np.geomspace(0.01, 10, 10):\n",
    "# for sigma in np.linspace(0.01, 100, 100):\n",
    "\n",
    "    for sampling in np.geomspace(1e-5, 1, 10):\n",
    "        for steps in np.arange(1,100, step=50):\n",
    "            curve_zoo.append(SubsampledGaussianCurve(sigma=sigma, sampling_probability=sampling, steps=steps))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zoo_df(zoo: list, clipped= True) -> pd.DataFrame:\n",
    "    dict_list = defaultdict(list)\n",
    "    for index, curve in enumerate(zoo):\n",
    "        for alpha, epsilon in zip(curve.alphas, curve.epsilons):\n",
    "            if block.epsilon(alpha) > 0:\n",
    "                dict_list[\"alphas\"].append(alpha)\n",
    "                dict_list[\"rdp_epsilons\"].append(epsilon)\n",
    "                if clipped:\n",
    "                    dict_list[\"normalized_epsilons\"].append(min(epsilon / block.epsilon(alpha), 1))\n",
    "                else:\n",
    "                    dict_list[\"normalized_epsilons\"].append(epsilon / block.epsilon(alpha))\n",
    "                dict_list[\"task\"].append(index)\n",
    "    return pd.DataFrame(dict_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = zoo_df(curve_zoo)\n",
    "\n",
    "\n",
    "tasks = pd.DataFrame(\n",
    "df.groupby('task')['normalized_epsilons'].agg(min)\n",
    ").reset_index()\n",
    "tasks = tasks.rename(columns={\"normalized_epsilons\": \"epsilon_min\"})\n",
    "tasks[\"epsilon_max\"] = df.groupby('task')['normalized_epsilons'].agg(max)\n",
    "tasks[\"epsilon_range\"] = tasks[\"epsilon_max\"] - tasks[\"epsilon_min\"]\n",
    "\n",
    "df = df.merge(tasks)\n",
    "df = df.query(\"epsilon_min < 1 and epsilon_min > 1e-6\")\n",
    "\n",
    "# TODO: should we also filter out the tiny tiny tasks? Some subsampled guassians are ridiculously small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.epsilon_max.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line(\n",
    "    df,\n",
    "    x=\"alphas\",\n",
    "    y=\"normalized_epsilons\",\n",
    "    color=\"task\",\n",
    "    log_y=True,\n",
    "    log_x=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indx = df.groupby('task')['normalized_epsilons'].idxmin()\n",
    "best_alpha = df.loc[indx]\n",
    "px.scatter(\n",
    "    best_alpha,\n",
    "    x=\"alphas\",\n",
    "    y=\"normalized_epsilons\",\n",
    "    color=\"task\",\n",
    "    log_y=True,\n",
    "    log_x=True,\n",
    "    title=\"Epsilon for the best alpha of each task\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(\n",
    "    df,\n",
    "    x=\"epsilon_min\",\n",
    "    # nbins=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(\n",
    "    df,\n",
    "    x=\"epsilon_max\",\n",
    "    nbins=20,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(\n",
    "    df,\n",
    "    x=\"epsilon_range\",\n",
    "    # nbins=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geometric distribution\n",
    "n_bins=20\n",
    "p = 0.01\n",
    "f = []\n",
    "for k in range(20):\n",
    "    f.append((1-p)**(k-1)*p)\n",
    "f = np.array(f)\n",
    "f = f/sum(f)\n",
    "px.line(f, title=f\"Geometric distribution with p={p} and variance {(1-p)/p**2:.2f}, mean {1/p:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples=500\n",
    "bin_ids = np.random.choice(n_bins, n_samples, p=f)\n",
    "\n",
    "def sample_from_bin(bin_id):\n",
    "    a = bin_id * (1/n_bins)\n",
    "    b = a + (1/n_bins)\n",
    "    bin_tasks = df.query(f\"epsilon_range > {a} and epsilon_range <= {b}\").task.unique()\n",
    "    return np.random.choice(bin_tasks)\n",
    "\n",
    "workload = [sample_from_bin(i) for i in bin_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line(\n",
    "    df.query(f\"task in {workload}\"),\n",
    "    x=\"alphas\",\n",
    "    y=\"normalized_epsilons\",\n",
    "    color=\"task\",\n",
    "    log_y=True,\n",
    "    log_x=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Negative binomial distribution\n",
    "# Probably pointless since the epsilon_min are not uniform anyway\n",
    "n_bins=20\n",
    "mu = 2\n",
    "# alpha = 10\n",
    "# beta = mu * alpha\n",
    "\n",
    "p = 0.01\n",
    "r = mu * (1-p) / p\n",
    "f = []\n",
    "for k in range(20):\n",
    "    f.append(\n",
    "        scipy.special.binom(k + r - 1, k) * (1-p)**r * p**k\n",
    "        # k **(alpha - 1) * np.exp(-beta * k) * beta ** alpha / scipy.special.gamma(alpha)\n",
    "    )\n",
    "f = np.array(f)\n",
    "f = f/sum(f)\n",
    "\n",
    "empirical_mean = np.average(np.array(range(n_bins)), weights=f)\n",
    "empirical_var = np.average(np.array(range(n_bins)) ** 2, weights=f) - empirical_mean ** 2\n",
    "px.line(f, title=f\"NBN distribution with p={p}. Empirical var {empirical_var:.2f}, mean {empirical_mean:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just a boring Gaussian?\n",
    "n_bins=20\n",
    "mu = 10\n",
    "sigma = 1\n",
    "f = []\n",
    "for k in range(20):\n",
    "    f.append(\n",
    "        scipy.stats.norm.pdf(k, mu, sigma)\n",
    "        # scipy.special.binom(k + r - 1, k) * (1-p)**r * p**k\n",
    "        # k **(alpha - 1) * np.exp(-beta * k) * beta ** alpha / scipy.special.gamma(alpha)\n",
    "    )\n",
    "f = np.array(f)\n",
    "f = f/sum(f)\n",
    "\n",
    "empirical_mean = np.average(np.array(range(n_bins)), weights=f)\n",
    "empirical_var = np.average(np.array(range(n_bins)) ** 2, weights=f) - empirical_mean ** 2\n",
    "px.line(f, title=f\"NBN distribution with p={p}. Empirical var {empirical_var:.2f}, mean {empirical_mean:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(\n",
    "    # df.query(\"epsilon_min > 0.3 and epsilon_min < 0.4\"),\n",
    "    df.query(\"epsilon_min > 0.3\"),\n",
    "    x=\"epsilon_range\",\n",
    "    nbins=20,\n",
    "    range_x=[0,1],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(\n",
    "    # df.query(\"epsilon_min > 0.3 and epsilon_min < 0.4\"),\n",
    "    df.query(\"epsilon_range > 0.1 and epsilon_range < 0.2\"),\n",
    "    x=\"epsilon_min\",\n",
    "    nbins=20,\n",
    "    range_x=[0,1],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(\n",
    "    # df.query(\"epsilon_min > 0.3 and epsilon_min < 0.4\"),\n",
    "    df.query(\"epsilon_range < 0.3\"),\n",
    "    x=\"epsilon_min\",\n",
    "    nbins=20,\n",
    "    range_x=[0,1],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Should we condition by epsilon_min (or epsilon_max)? Otherwise increasing the range variance will also increase the average size of the tasks. Well that's probably inevitable. Ok let's start with a first rough draft, we don't need the ultimate perfect metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_range_to_bin(r):\n",
    "    return int(r * n_bins)\n",
    "\n",
    "tasks[\"bin_id\"] = tasks[\"epsilon_range\"].apply(map_range_to_bin)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(tasks.groupby(\"bin_id\").count().reset_index().bin_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from experiments.ray.analysis import load_latest_ray_experiment\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf = load_latest_ray_experiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_block_std(path):\n",
    "    if \"sigma\" not in path:\n",
    "        return 0\n",
    "    return float(path.split(\"sigma\")[1])\n",
    "rdf[\"block_std\"] = rdf[\"tasks_path\"].apply(get_block_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(\n",
    "    rdf.sort_values(\"block_std\"),\n",
    "    x=\"block_std\",\n",
    "    y=\"n_allocated_tasks\",\n",
    "    color=\"scheduler_metric\",\n",
    "    width=800,\n",
    "    height=600,\n",
    "    log_x=True, \n",
    "    range_y=[0, 4000],\n",
    "    title=\"Heterogenous blocks curves offline\",\n",
    ")\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "eb9f88a12e8f66ffa940aa96de4342344a602b0c71bf9fbb297683183e48a1a1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
