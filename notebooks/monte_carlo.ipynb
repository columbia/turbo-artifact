{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting\n",
    "\n",
    "- We have k chunks to estimate\n",
    "- Each chunk i already has $m_i$ past results $R_{ij} \\sim Lap(1/n_i \\epsilon_{ij})$\n",
    "- Linear combination: $Q_{ij} := \\frac{n_i}{n} \\gamma_{ij}(q_i + R_{ij})$\n",
    "- We need $\\sum_j \\gamma_{ij} = 1$ for each chunk $i$ to have an unbiased estimate\n",
    "- Goal: output an estimate $Q = Q_{10} + \\dots + Q_{1m_1} +\\dots + Q_{k0} + \\dots + Q_{km_k}$\n",
    "- Accuracy constraint: $\\Pr[|Q-q|>\\alpha] < \\beta$\n",
    "- Simplifying budget constraint: $R_{i0} \\sim Lap(1/n_\\epsilon)$ (same budget for everyone!). That's a weird constraint if we have chunks that are already good, let's see if we can set some epsilons to infinity. In the general case we could try an ILP or even some gradient descent on the budget vector?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minimum_variance(epsilons, noises, chunk_sizes):\n",
    "    n_chunks = len(epsilons)\n",
    "    chunk_noises = np.zeros(n_chunks)\n",
    "    for chunk_id in range(n_chunks):\n",
    "        # The variance has an extra 2/n_i^2 factor but it doesn't matter at the chunk level\n",
    "        laplace_coefficients = epsilons[chunk_id] ** 2\n",
    "        # See optimal variance reduction and lemma in Overleaf\n",
    "        laplace_coefficients = laplace_coefficients / sum(laplace_coefficients)\n",
    "        chunk_noises[chunk_id] = np.dot(laplace_coefficients, noises[chunk_id])\n",
    "        \n",
    "    chunk_coefficients = chunk_sizes / sum(chunk_sizes)\n",
    "    aggregated_noise_total = np.dot(chunk_coefficients, chunk_noises)\n",
    "    return aggregated_noise_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: given epsilon and past results, find beta\n",
    "\n",
    "def monte_carlo_beta(existing_epsilons, chunk_sizes, fresh_epsilon, alpha, N=1_000_000):\n",
    "    \n",
    "    # Add fresh epsilon\n",
    "    epsilons = [\n",
    "        np.append(eps_by_chunk, fresh_epsilon) for eps_by_chunk in existing_epsilons\n",
    "    ]\n",
    "    \n",
    "    # TODO: heuristic to drop some chunks?\n",
    "    \n",
    "    # Vectorized code with a batch dimension corresponding to N\n",
    "    n_chunks = len(epsilons)\n",
    "    n = sum(chunk_sizes)\n",
    "    chunk_noises = np.zeros((N, n_chunks))\n",
    "    for chunk_id in range(n_chunks):\n",
    "        # The final laplace scale (Q_ij), already scaled by n_i/n * eps^2/sum(eps^2)\n",
    "        single_chunk_laplace_scale = epsilons[chunk_id] / (n * np.sum(epsilons[chunk_id] ** 2))\n",
    "        laplace_scale = np.repeat([single_chunk_laplace_scale], N, axis=0)\n",
    "        laplace_noises = np.random.laplace(scale=laplace_scale)\n",
    "        \n",
    "        \n",
    "        # Optimal average for that chunk, N times\n",
    "        chunk_noises[:, chunk_id] = np.sum(laplace_noises, axis=1)\n",
    "        \n",
    "    aggregated_noise_total = np.sum(chunk_noises, axis=1)\n",
    "    beta = np.sum(aggregated_noise_total > alpha) / N\n",
    "    return beta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3511366"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "existing_epsilons = [\n",
    "    np.array([1, 0.5, 2]),\n",
    "    np.array([0.3, 2.1])\n",
    "]\n",
    "\n",
    "chunk_sizes = [100, 200]\n",
    "fresh_epsilon = 0.1\n",
    "alpha = 0.001\n",
    "\n",
    "monte_carlo_beta(existing_epsilons, chunk_sizes, fresh_epsilon, alpha, N=10_000_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: binary search for epsilon"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "precycle-GKqJt2VE-py3.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
