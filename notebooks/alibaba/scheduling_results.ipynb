{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload \n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from privacypacking.utils.utils import load_logs\n",
    "import pandas as pd\n",
    "from experiments.ray.analysis import load_ray_experiment, load_latest_ray_experiment, load_latest_scheduling_results, load_latest_scheduling_results, load_latest_ray_experiment\n",
    "import plotly.express as px\n",
    "from privacypacking.budget.curves import  LaplaceCurve, GaussianCurve, SubsampledGaussianCurve\n",
    "from privacypacking.budget import Budget, Task, Block\n",
    "from privacypacking.schedulers.metrics import OverflowRelevance, FlatRelevance\n",
    "from privacypacking.budget.block_selection import RandomBlocks\n",
    "from privacypacking.utils.plot import plot_budgets\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import numpy as np\n",
    "from experiments.ray.analysis import get_percentiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_latest_scheduling_results(expname=\"ray/run_and_report_2022-04-06_17-27-02\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.ecdf(\n",
    "    df.query(\"max_blocks == 200 and data_lifetime == 1 and T == 10 and scheduler_metric == 'ArgmaxKnapsack' and allocated\"),\n",
    "    x=\"n_blocks\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks_df = pd.read_csv(\"/home/pierre/privacypacking/data/alibaba-privacy-workload/outputs/privacy_tasks.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.ecdf(\n",
    "    df.query(\"max_blocks == 200 and data_lifetime == 1 and T == 10 and scheduler_metric == 'DominantShares' and allocated\"),\n",
    "    x=\"n_blocks\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most allocated tasks have below 10 blocks, because we have T=10? The data lifetime is way too small, basically no unlocking so after T = 10 all the previous budget is unlocked and eaten up, not much space for anything else. Result: DPF does not fall into multiblock traps.\n",
    "\n",
    "Conclusion: you should scale up everything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.ecdf(\n",
    "    df.query(\"max_blocks == 200 and data_lifetime == 1 and T == 10\"),\n",
    "    x=\"n_blocks\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listify(row):\n",
    "    return list(map(float, row.strip('][').split(', ')))\n",
    "tasks_df[\"alphas\"] = tasks_df[\"alphas\"].apply(listify)\n",
    "tasks_df[\"rdp_epsilons\"] = tasks_df[\"rdp_epsilons\"].apply(listify)\n",
    "tasks_df[\"normalized_rdp_epsilons\"] = tasks_df[\"normalized_rdp_epsilons\"].apply(listify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks_df[\"epsilon_min\"] = tasks_df[\"normalized_rdp_epsilons\"].apply(min)\n",
    "tasks_df[\"epsilon_max\"] = tasks_df[\"normalized_rdp_epsilons\"].apply(max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(\n",
    "    tasks_df,\n",
    "    x=\"epsilon_max\",\n",
    "    y=\"n_blocks\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(\n",
    "    tasks_df,\n",
    "    x=\"epsilon_min\",\n",
    "    y=\"n_blocks\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf = load_ray_experiment(Path(\"/home/pierre/privacypacking/logs/ray/run_and_report_2022-04-06_17-27-02\"))\n",
    "# rdf[\"scheduler_metric\"] = rdf.apply(lambda row: row.scheduler_metric if row.scheduler == \"basic_scheduler\" else \"Simplex\", axis=1)\n",
    "px.line(\n",
    "    rdf.query(\"data_lifetime == 1 and max_blocks == 200\").sort_values(\"T\"),\n",
    "    x=\"T\",\n",
    "    y=\"n_allocated_tasks\",\n",
    "    color=\"scheduler_metric\",\n",
    "    log_x=True,\n",
    "    width=800,\n",
    "    height=600,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8eab72c90ef7b6cf7a47cf9058599fe69878ae5c291bf7d8c10fb9498bc1b89e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('privacypacking-DDudTmDF-py3.8')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
