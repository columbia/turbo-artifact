{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload \n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from privacypacking.utils.utils import load_logs\n",
    "import pandas as pd\n",
    "from experiments.ray.analysis import load_ray_experiment, load_latest_ray_experiment, load_latest_scheduling_results, load_latest_scheduling_results, load_latest_ray_experiment\n",
    "import plotly.express as px\n",
    "from privacypacking.budget.curves import  LaplaceCurve, GaussianCurve, SubsampledGaussianCurve\n",
    "from privacypacking.budget import Budget, Task, Block\n",
    "from privacypacking.schedulers.metrics import OverflowRelevance, FlatRelevance\n",
    "from privacypacking.budget.block_selection import RandomBlocks\n",
    "from privacypacking.utils.plot import plot_budgets\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import numpy as np\n",
    "from experiments.ray.analysis import get_percentiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = load_latest_scheduling_results(expname=\"ray/run_and_report_2022-04-06_17-27-02\")\n",
    "df = load_latest_scheduling_results(expname=\"ray/run_and_report_2022-04-06_22-35-08\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_df = df.copy()\n",
    "df = original_df.query(\"data_lifetime == 100 and max_blocks == 100 and T == 10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.ecdf(\n",
    "    df.query(\"scheduler_metric == 'ArgmaxKnapsack' and allocated\"),\n",
    "    x=\"n_blocks\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.ecdf(\n",
    "    df.query(\"scheduler_metric == 'DominantShares' and allocated\"),\n",
    "    x=\"n_blocks\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most allocated tasks have below 10 blocks, because we have T=10? The data lifetime is way too small, basically no unlocking so after T = 10 all the previous budget is unlocked and eaten up, not much space for anything else. Result: DPF does not fall into multiblock traps.\n",
    "\n",
    "Conclusion: you should scale up everything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.ecdf(\n",
    "    df,\n",
    "    x=\"n_blocks\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks_df = pd.read_csv(\"/home/pierre/privacypacking/data/alibaba-privacy-workload/outputs/privacy_tasks.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listify(row):\n",
    "    return list(map(float, row.strip('][').split(', ')))\n",
    "tasks_df[\"alphas\"] = tasks_df[\"alphas\"].apply(listify)\n",
    "tasks_df[\"rdp_epsilons\"] = tasks_df[\"rdp_epsilons\"].apply(listify)\n",
    "tasks_df[\"normalized_rdp_epsilons\"] = tasks_df[\"normalized_rdp_epsilons\"].apply(listify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks_df[\"epsilon_min\"] = tasks_df[\"normalized_rdp_epsilons\"].apply(min)\n",
    "tasks_df[\"epsilon_max\"] = tasks_df[\"normalized_rdp_epsilons\"].apply(max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(\n",
    "    tasks_df,\n",
    "    x=\"epsilon_max\",\n",
    "    y=\"n_blocks\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(\n",
    "    tasks_df,\n",
    "    x=\"epsilon_min\",\n",
    "    y=\"n_blocks\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rdf = load_ray_experiment(Path(\"/home/pierre/privacypacking/logs/ray/run_and_report_2022-04-06_22-35-08\"))\n",
    "rdf = load_ray_experiment(Path(\"/home/pierre/privacypacking/logs/ray/run_and_report_2022-04-07_08-24-11\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rdf = load_ray_experiment(Path(\"/home/pierre/privacypacking/logs/ray/run_and_report_2022-04-06_17-27-02\"))\n",
    "# rdf[\"scheduler_metric\"] = rdf.apply(lambda row: row.scheduler_metric if row.scheduler == \"basic_scheduler\" else \"Simplex\", axis=1)\n",
    "fig = px.line(\n",
    "    # rdf.query(\"data_lifetime == 50 and max_blocks == 400\").sort_values(\"T\"),\n",
    "    rdf.sort_values([\"data_lifetime\", \"max_blocks\", \"T\"]),\n",
    "    x=\"T\",\n",
    "    y=\"n_allocated_tasks\",\n",
    "    color=\"scheduler_metric\",\n",
    "    log_x=True,\n",
    "    width=800,\n",
    "    height=600,\n",
    "    markers=True,\n",
    "    facet_col=\"data_lifetime\",\n",
    "    facet_row=\"max_blocks\",\n",
    ")\n",
    "fig.update_yaxes(rangemode=\"tozero\")\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf = load_latest_scheduling_results(expname=\"ray/run_and_report_2022-04-07_08-24-11\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = sdf.query(\"allocated\").groupby([\"data_lifetime\", \"max_blocks\",\"scheduler_metric\",\"T\"]).agg({\"n_blocks\": \"mean\"}).reset_index()\n",
    "m = m.rename(columns={\"n_blocks\": \"avg_n_blocks\"})\n",
    "s = sdf.query(\"allocated\").groupby([\"data_lifetime\", \"max_blocks\",\"scheduler_metric\",\"T\"]).agg({\"n_blocks\": \"std\"}).reset_index()\n",
    "s = s.rename(columns={\"n_blocks\": \"std_n_blocks\"})\n",
    "m = m.merge(s, on = [\"data_lifetime\", \"max_blocks\",\"scheduler_metric\",\"T\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(\n",
    "    # rdf.query(\"data_lifetime == 50 and max_blocks == 400\").sort_values(\"T\"),\n",
    "    m.sort_values([\"data_lifetime\", \"max_blocks\", \"T\"]),\n",
    "    x=\"T\",\n",
    "    y=\"avg_n_blocks\",\n",
    "    error_y=\"std_n_blocks\",\n",
    "    color=\"scheduler_metric\",\n",
    "    log_x=True,\n",
    "    width=800,\n",
    "    height=600,\n",
    "    markers=True,\n",
    "    facet_col=\"data_lifetime\",\n",
    "    facet_row=\"max_blocks\",\n",
    ")\n",
    "fig.update_yaxes(rangemode=\"tozero\")\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Surprisingly, FCFS allocates small tasks (in number of blocks). Probably because it is wasting so much space with poor RDP packing that it has no choice but using small tasks?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = sdf.groupby([\"data_lifetime\", \"max_blocks\",\"scheduler_metric\",\"T\"]).agg({\"n_blocks\": \"mean\"}).reset_index()\n",
    "m = m.rename(columns={\"n_blocks\": \"avg_n_blocks\"})\n",
    "s = sdf.groupby([\"data_lifetime\", \"max_blocks\",\"scheduler_metric\",\"T\"]).agg({\"n_blocks\": \"std\"}).reset_index()\n",
    "s = s.rename(columns={\"n_blocks\": \"std_n_blocks\"})\n",
    "m = m.merge(s, on = [\"data_lifetime\", \"max_blocks\",\"scheduler_metric\",\"T\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The task distribution changes when we change the max number of blocks: when we have only 50 blocks, we drop tasks that ask more than the number of blocks at generation time because they have no chance of being allocated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(\n",
    "    # rdf.query(\"data_lifetime == 50 and max_blocks == 400\").sort_values(\"T\"),\n",
    "    m.sort_values([\"data_lifetime\", \"max_blocks\", \"T\"]),\n",
    "    x=\"T\",\n",
    "    y=\"avg_n_blocks\",\n",
    "    error_y=\"std_n_blocks\",\n",
    "    color=\"scheduler_metric\",\n",
    "    log_x=True,\n",
    "    width=800,\n",
    "    height=600,\n",
    "    markers=True,\n",
    "    facet_col=\"data_lifetime\",\n",
    "    facet_row=\"max_blocks\",\n",
    ")\n",
    "fig.update_yaxes(rangemode=\"tozero\")\n",
    "fig"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8eab72c90ef7b6cf7a47cf9058599fe69878ae5c291bf7d8c10fb9498bc1b89e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('privacypacking-DDudTmDF-py3.8')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
