{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REPO_ROOT = Path(\"../../\").resolve()\n",
    "DATA_DIR = str(REPO_ROOT) + '/data/alibaba/cluster-trace-gpu-v2020/data/'\n",
    "\n",
    "dfg = pd.read_csv(DATA_DIR + 'workers_with_workload.csv')\n",
    "# dfg = pd.read_csv(\"tasks_with_workload.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model as a proxy for privacy mechanism (various parameters of DPSGD, Gaussian, Laplace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(\n",
    "    dfg,\n",
    "    x=\"group\",\n",
    "    # y=\"inst_id\",\n",
    "    title=\"Number of tasks per group (group = recurring task)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(\n",
    "    dfg,\n",
    "    x=\"workload\",\n",
    "    # y=\"inst_id\",\n",
    "    title=\"Number of tasks for each model architecture (workload)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most jobs have only one task, but some have multiple tasks.\n",
    "We might want to keep training tasks only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_counts = dfg[[\"start_time\", \"job_name\"]].groupby(\"job_name\").count().reset_index()\n",
    "job_counts[\"n_tasks\"] = job_counts[\"start_time\"]\n",
    "job_counts=job_counts.drop(\"start_time\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.ecdf(\n",
    "    job_counts,\n",
    "    x=\"n_tasks\",\n",
    "    # color=\"task_name\",\n",
    "    log_x=True,\n",
    "    title=\"# tasks per job\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(\n",
    "    dfg,\n",
    "    x=\"task_name\",\n",
    "    # y=\"inst_id\",\n",
    "    title=\"Number of tasks per task type\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfg.job_name.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfg.user.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_counts = dfg[[\"user\", \"job_name\"]].groupby(\"user\").count().reset_index()\n",
    "user_counts[\"n_tasks\"] = user_counts[\"job_name\"]\n",
    "user_counts=user_counts.drop(\"job_name\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.bar(\n",
    "    user_counts.sort_values(\"n_tasks\"),\n",
    "    x=\"user\",\n",
    "    y=\"n_tasks\",\n",
    "    # y=\"inst_id\",\n",
    "    title=\"Number of tasks per user\",\n",
    "    log_y=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfg.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfg.task_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computational resources\n",
    "\n",
    "inst_num: number of instances launched by the task.\n",
    "\n",
    "plan_cpu: number of CPU cores requested in percentage (i.e., 600.0 is 6 vCPU cores) .\n",
    "\n",
    "plan_mem: GB of main memory requested.\n",
    "\n",
    "plan_gpu: number of GPUs requested in percentage (i.e., 50.0 is 50% GPU).\n",
    "\n",
    "gpu_type: type of GPUs assigned to this task. MISC is short for \"miscellaneous\", indicating GPUs of older generations, e.g., NVIDIA Tesla K40m, K80, M60.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of instances (Docker containers) per task -> Proxy for privacy?\n",
    "\n",
    "- or cpu\n",
    "\n",
    "- Rescale to fit epsilon between 0.1 and 10.\n",
    "- how to set delta? *maybe according to the task type* \n",
    "- Given epsilon, delta and a mechanism type, compute the corresponding RDP curve for the actual task demand\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.ecdf(\n",
    "    dfg,\n",
    "    x=\"inst_num\",\n",
    "    color=\"workload\",\n",
    "    log_x=True,\n",
    "    title=\"# containers per task\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPU type as a proxy for profit (or privacy)?\n",
    "\n",
    "High-end GPU (V100) are reserved for expensive tasks.\n",
    "P100 and T4 are intermediary GPUs.\n",
    "MISC are GPUs from older generations, quite cheap.\n",
    "\n",
    "\n",
    "- [ ] Check if priority\n",
    "\n",
    "This could give us a discrete mapping:\n",
    "- V100M32: profit = 100\n",
    "- V100: profit = 10\n",
    "- P100: profit = 5\n",
    "- T4: profit = 1\n",
    "- MISC: profit = 0.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(\n",
    "    dfg,\n",
    "    x=\"gpu_type\",\n",
    "    color=\"workload\",\n",
    "    title=\"Type of GPU for each type of model\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.ecdf(\n",
    "    dfg,\n",
    "    x=\"plan_cpu\",\n",
    "    color=\"workload\",\n",
    "    log_x=True,\n",
    "    title=\"# cpu per task\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.ecdf(\n",
    "    dfg,\n",
    "    x=\"plan_gpu\",\n",
    "    color=\"workload\",\n",
    "    log_x=True,\n",
    "    title=\"# GPU per task\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory as a proxy for the number of blocks?\n",
    "\n",
    "This metric might be close to the number of data points actually consumed.\n",
    "\n",
    "Problem:\n",
    "- There is not too much variability, most tasks ask between 1GB and 100GB of memory\n",
    "- RAM is not necessarily related to the size of the dataset, since we usually don't load it all at once in memory\n",
    "- Most instances of a given workload have the same memory request (e.g 80% of CTR instances ask for 2GB). Strong correlation between the curve type and the amplitude. This might actually be quite realistic.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.ecdf(\n",
    "    dfg,\n",
    "    x=\"plan_mem\",\n",
    "    color=\"workload\",\n",
    "    log_x=True,\n",
    "    title=\"RAM per task (in GB)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Runtime\n",
    "\n",
    "Not sure it is reasonable to use it as a proxy for number of blocks or privacy budget. Too many orders of magnitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.ecdf(\n",
    "    dfg,\n",
    "    x=\"runtime\",\n",
    "    color=\"workload\",\n",
    "    log_x=True,\n",
    "    title=\"Runtime per task (in seconds)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The missing piece: what proxy for the block range?\n",
    "\n",
    "Even if we have a proxy for the number of blocks (e.g. memory or runtime), we still need to know *which* blocks are requested to run a simulation.\n",
    "\n",
    "- The $N$ latest blocks?\n",
    "- $N$ random blocks chosen among the $2N$ latest blocks?\n",
    "- Some sort of tumbling window?\n",
    "- Any random $N$ blocks since the beginning of time?\n",
    "\n",
    "We will likely need some TFX statistics to decide this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arrival time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(\n",
    "    dfg,\n",
    "    x=\"start_date\",\n",
    "    nbins=100,\n",
    "    title=\"arrival time, starting at timestamp 0\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(\n",
    "    dfg[dfg[\"start_date\"] < '1970-01-15'],\n",
    "    x=\"start_date\",\n",
    "    color=\"workload\",\n",
    "    title=\"arrival time for 1 day, per model type\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurring pipelines\n",
    "\n",
    "(Not a priority now, but might be useful later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(\n",
    "    dfg,\n",
    "    x=\"group\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = dfg.groupby(['group']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.ecdf(\n",
    "    groups,\n",
    "    x=\"job_name\",\n",
    "    log_x=True,\n",
    "    title=\"CDF of the number of instances for each group. <br> We can confirm the paper's claim that 65% of the instances repeat more than 5 times\" \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sg = groups.sort_values([\"job_name\"], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sg.iloc[0].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = [sg.iloc[10 * i].name for i in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(\n",
    "    dfg.query(f\"start_date < '1970-01-17' and group in {groups}\"),\n",
    "#     dfg[(dfg[\"start_date\"]<'1970-01-15') & (dfg[\"group\"] == '02a6709662bff12fea88270e3eb1231d')],\n",
    "    x=\"start_date\",\n",
    "    color=\"group\",\n",
    "    nbins=1000,\n",
    "    title=\"Launch time for the top 3 recurring tasks during the first 3 days\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8eab72c90ef7b6cf7a47cf9058599fe69878ae5c291bf7d8c10fb9498bc1b89e"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
