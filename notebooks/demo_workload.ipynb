{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload \n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from privacypacking.utils.utils import load_logs, global_metrics\n",
    "import pandas as pd\n",
    "from experiments.ray.analysis import load_tasks, load_ray_experiment, load_latest_ray_experiment, load_latest_scheduling_results, load_latest_scheduling_results, load_latest_ray_experiment, load_scheduling_queue\n",
    "import plotly.express as px\n",
    "from privacypacking.budget.curves import  LaplaceCurve, GaussianCurve, SubsampledGaussianCurve\n",
    "from privacypacking.budget import Budget, Task, Block\n",
    "from privacypacking.schedulers.metrics import OverflowRelevance, FlatRelevance\n",
    "from privacypacking.budget.block_selection import RandomBlocks\n",
    "from privacypacking.utils.plot import plot_budgets\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import numpy as np\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.io as pio\n",
    "pio.renderers.default = \"iframe\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_latest_scheduling_results(alphas=True, tasks_dir=\"/home/pierre/privacypacking/data/demo_workload/tasks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = df[[\"id\",\"task\",\"allocated\",\"metric\"]].drop_duplicates(subset=['id', 'metric']).groupby([\"task\",\"metric\"]).agg([np.sum, \"count\"])\n",
    "grouped = grouped.reset_index()\n",
    "grouped[\"n_allocated\"] = grouped[\"allocated\"][\"sum\"]\n",
    "grouped[\"total\"] = grouped[\"allocated\"][\"count\"]\n",
    "grouped = grouped.drop([\"id\", \"allocated\"], axis=1)\n",
    "grouped[\"n_rejected\"] = grouped[\"total\"] - grouped[\"n_allocated\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.bar(grouped[[\"metric\", \"n_allocated\"]].groupby(\"metric\").sum().reset_index(), \n",
    "         x = \"metric\",\n",
    "         y = \"n_allocated\",\n",
    "         title = 'Total number of tasks allocated per scheduler', \n",
    "        # facet_col=\"metric\",\n",
    "        #     facet_col_wrap=2,\n",
    "            # height=600,\n",
    "            width=1000\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.bar(grouped, \n",
    "         x = \"task\",\n",
    "         y = [\"n_allocated\", \"n_rejected\"],\n",
    "         title = 'Type of task allocated per scheduler', \n",
    "        facet_col=\"metric\",\n",
    "            facet_col_wrap=2,\n",
    "            height=600,\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.bar(\n",
    "    # df.query(\"allocated\"),\n",
    "    df.query(\"metric == 'VectorizedBatchOverflowRelevance'\"),\n",
    "    x=\"blockid_alpha\",\n",
    "    y=\"normalized_epsilon\",\n",
    "    range_y=[0,20],\n",
    "#     color=\"log_id\",\n",
    "    color=\"task\",\n",
    "    # barmode=\"group\",\n",
    "    # pattern_shape=\"allocated\",\n",
    "    # facet_col=\"metric\",\n",
    "    facet_col_wrap=1,\n",
    "    height=500,\n",
    "    title=\"All demands per block and alpha (workload)\"\n",
    "#     animation_frame=\"id\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.query(\"allocated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.bar(\n",
    "    df.query(\"allocated\").sort_values(\"blockid_alpha\"),\n",
    "    x=\"blockid_alpha\",\n",
    "    y=\"normalized_epsilon\",\n",
    "    range_y=[0,3],\n",
    "    range_x=[0, 5 * 5],\n",
    "#     color=\"log_id\",\n",
    "    color=\"task\",\n",
    "    # barmode=\"group\",\n",
    "    # pattern_shape=\"allocated\",\n",
    "    facet_col=\"metric\",\n",
    "    facet_col_wrap=1,\n",
    "    height=500,\n",
    "    title=\"Allocated tasks per block and alpha\"\n",
    "#     animation_frame=\"id\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.bar(\n",
    "    df.query(\"allocated and metric == 'BatchOverflowRelevance'\").sort_values([\"allocation_index\", \"blockid_alpha\"]),\n",
    "    x=\"blockid_alpha\",\n",
    "    y=\"normalized_epsilon\",\n",
    "    range_y=[0,3],\n",
    "    range_x=[0, 5 * 5],\n",
    "#     color=\"log_id\",\n",
    "    color=\"task\",\n",
    "    # barmode=\"group\",\n",
    "    # pattern_shape=\"allocated\",\n",
    "    # facet_col=\"metric\",\n",
    "    # facet_col_wrap=1,\n",
    "    height=500,\n",
    "    title=\"Allocated tasks per block and alpha\",\n",
    "    animation_frame=\"allocation_index\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why does overflow relevance sometimes allocate short flat instead of bumpy tasks??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.query(\"allocated and metric == 'BatchOverflowRelevance' and blockid_alpha == '002-08'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inefficient approach first: duplicate the rows for each scheduling time\n",
    "sdf = df.query(\"allocated and metric == 'BatchOverflowRelevance'\")\n",
    "len(sdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf.scheduling_time.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(sdf, x=\"scheduling_time\", nbins=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduling_steps = sdf.scheduling_time.unique()\n",
    "scheduling_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf[\"scheduled_at_or_before\"] = sdf.scheduling_time.apply(lambda scheduling_time: [i for i in scheduling_steps if i >= scheduling_time])\n",
    "sdf = sdf.explode(\"scheduled_at_or_before\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.bar(\n",
    "    sdf.sort_values([\"blockid_alpha\", \"scheduled_at_or_before\",\"T\"]),\n",
    "    x=\"blockid_alpha\",\n",
    "    y=\"normalized_epsilon\",\n",
    "    range_y=[0,3],\n",
    "    range_x = [0, 20 * 5],\n",
    "    color=\"task\",\n",
    "    facet_col=\"scheduled_at_or_before\",\n",
    "    facet_col_wrap=1,\n",
    "    height=600,\n",
    "    width=1200,\n",
    "    # animation_frame=\"scheduled_at_or_before\",\n",
    "    title=\"BatchOverflowRelevance allocation mix for different scheduling step sizes<br><sup>Only showing 4 alphas per block</sup>\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why on earth are the blocks not ordered properly?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queue = load_scheduling_queue()\n",
    "tasks = load_tasks(tasks_dir=\"/home/pierre/privacypacking/data/demo_workload/tasks\")\n",
    "# top_queue = defaultdict()\n",
    "# for row in queue.itertuples():\n",
    "#     for task_id, metric_val in row.ids_and_metrics:\n",
    "#         print(task_id, metric_val)\n",
    "def zip_positions(l):\n",
    "    o = []\n",
    "    i = 0\n",
    "    for a,b in l:\n",
    "        o.append((a,b,i))\n",
    "        i+=1\n",
    "    return o\n",
    "\n",
    "queue[\"ids_and_metrics\"] = queue.ids_and_metrics.apply(zip_positions)\n",
    "queue.head()\n",
    "queue = queue.explode(\"ids_and_metrics\")\n",
    "queue[\"id\"] = queue.ids_and_metrics.apply(lambda x: x[0])\n",
    "queue[\"efficiency\"] = queue.ids_and_metrics.apply(lambda x: x[1])\n",
    "queue[\"position_in_queue\"] = queue.ids_and_metrics.apply(lambda x: x[2])\n",
    "\n",
    "queue = queue.merge(tasks, on=\"id\")\n",
    "\n",
    "# Cap infinite profits\n",
    "queue[\"efficiency\"] = queue[\"efficiency\"].apply(lambda x: 1000 if x > 1000 else x)\n",
    "# px.bar(\n",
    "#     queue,\n",
    "#     x=\"position_in_queue\",\n",
    "#     y=\"efficiency\",\n",
    "#     range_y=[1e-3, 1e3],\n",
    "#     log_y=True,\n",
    "#     # range_x = [0, 20 * 5],\n",
    "#     color=\"task\",\n",
    "#     facet_col=\"T\",\n",
    "#     facet_col_wrap=1,\n",
    "#     height=600,\n",
    "#     width=1200,\n",
    "#     animation_frame=\"scheduling_time\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Warning: the slider doesn't seem reliable (misses some colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queue.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queue.first_block_id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.bar(\n",
    "    queue.query(\"metric == 'BatchOverflowRelevance'\"),\n",
    "    x=\"position_in_queue\",\n",
    "    y=\"id\",\n",
    "    # range_y=[1e-3, 1e3],\n",
    "    # log_y=True,\n",
    "    hover_name=\"first_block_id\",\n",
    "    # range_x = [0, 20 * 5],\n",
    "    color=\"task\",\n",
    "    facet_col=\"scheduling_time\",\n",
    "    facet_col_wrap=1,\n",
    "    height=600,\n",
    "    width=1200,\n",
    "    animation_frame=\"iteration_counter\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.bar(\n",
    "    sdf.sort_values([\"blockid_alpha\", \"scheduled_at_or_before\",\"T\"]),\n",
    "    x=\"blockid_alpha\",\n",
    "    y=\"normalized_epsilon\",\n",
    "    range_y=[0,3],\n",
    "    range_x = [0, 20 * 5],\n",
    "    color=\"task\",\n",
    "    facet_col=\"scheduled_at_or_before\",\n",
    "    facet_col_wrap=1,\n",
    "    height=600,\n",
    "    width=1200,\n",
    "    # animation_frame=\"scheduled_at_or_before\",\n",
    "    title=\"BatchOverflowRelevance allocation mix for different scheduling step sizes<br><sup>Only showing 4 alphas per block</sup>\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: allocation iteration by iteration. Then, understand why infinite metrics come from, and why they are not scheduled if they are infinite!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's compare the queue for different schedulers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_scheduling_queue()\n",
    "tasks = load_tasks(tasks_dir=\"/home/pierre/privacypacking/data/mixed_curves/tasks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queue = df.query(\"iteration_counter == 1 and T == 1.0 and scheduling_time == 2 \")\n",
    "# top_queue = defaultdict()\n",
    "# for row in queue.itertuples():\n",
    "#     for task_id, metric_val in row.ids_and_metrics:\n",
    "#         print(task_id, metric_val)\n",
    "def zip_positions(l):\n",
    "    o = []\n",
    "    i = 0\n",
    "    for a,b in l:\n",
    "        o.append((a,b,i))\n",
    "        i+=1\n",
    "    return o\n",
    "\n",
    "queue[\"ids_and_metrics\"] = queue.ids_and_metrics.apply(zip_positions)\n",
    "queue.head()\n",
    "queue = queue.explode(\"ids_and_metrics\")\n",
    "queue[\"id\"] = queue.ids_and_metrics.apply(lambda x: x[0])\n",
    "queue[\"efficiency\"] = queue.ids_and_metrics.apply(lambda x: x[1])\n",
    "queue[\"position_in_queue\"] = queue.ids_and_metrics.apply(lambda x: x[2])\n",
    "\n",
    "queue = queue.merge(tasks, on=\"id\")\n",
    "px.bar(\n",
    "    queue,\n",
    "    x=\"position_in_queue\",\n",
    "    y=\"efficiency\",\n",
    "    range_y=[1e-3, 1e3],\n",
    "    log_y=True,\n",
    "    # range_x = [0, 20 * 5],\n",
    "    color=\"task\",\n",
    "    facet_col=\"metric\",\n",
    "    facet_col_wrap=1,\n",
    "    height=600,\n",
    "    width=1200,\n",
    "    # animation_frame=\"scheduling_time\",\n",
    "    orientation='v'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf = load_ray_experiment(Path(\"/home/pierre/privacypacking/logs/ray/run_and_report_2021-11-29_10-42-15\"))\n",
    "px.line(\n",
    "    ddf.sort_values(\"T\"),\n",
    "    x=\"T\",\n",
    "    y=\"n_allocated_tasks\",\n",
    "    color=\"scheduler_metric\",\n",
    "    log_x=True,\n",
    "    width=1_000,\n",
    "    title=\"Allocated tasks depending on the scheduling step size<br><sup>Online mixed curves, 20 blocks, no initial blocks, 100 tasks per block on average, lifetime = 5 blocks, N = 10_000 (i.e. almost continuous unlocking)</sup>\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf = load_latest_scheduling_results(alphas=True, tasks_dir=\"/home/pierre/privacypacking/data/mixed_curves/tasks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf.drop_duplicates(subset=[\"id\", \"T\", \"metric\"]).id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delay_df = sdf.drop_duplicates(subset=[\"id\", \"T\", \"metric\"])\n",
    "delay_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line(\n",
    "    delay_df.groupby([\"T\", \"metric\"]).mean().reset_index().sort_values(\"T\"),\n",
    "    x=\"T\",\n",
    "    y=\"scheduling_delay\",\n",
    "    color=\"metric\",\n",
    "    log_x=True,\n",
    "    width=1_000,\n",
    "    title=\"Average delay of allocated tasks, depending on the scheduling step size<br><sup>Online mixed curves, 20 blocks, no initial blocks, 100 tasks per block on average, lifetime = 5 blocks, N = 10_000 (i.e. almost continuous unlocking)<br> FCFS is 'batched FCFS'</sup>\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf = load_ray_experiment(Path(\"/home/pierre/privacypacking/logs/ray/run_and_report_2021-11-30_18-08-51\"))\n",
    "px.line(\n",
    "    ddf.sort_values(\"T\"),\n",
    "    x=\"T\",\n",
    "    y=\"n_allocated_tasks\",\n",
    "    color=\"scheduler_metric\",\n",
    "    log_x=True,\n",
    "    width=1_000,\n",
    "    title=\"Allocated tasks depending on the scheduling step size<br><sup>Online mixed curves, 20 blocks, no initial blocks, 100 tasks per block on average, lifetime = 5 blocks, N = 10_000 (i.e. almost continuous unlocking)</sup>\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf = load_ray_experiment(Path(\"/home/pierre/privacypacking/logs/ray/run_and_report_2021-11-29_22-26-18\"))\n",
    "px.line(\n",
    "    ddf.sort_values(\"T\"),\n",
    "    x=\"T\",\n",
    "    y=\"n_allocated_tasks\",\n",
    "    color=\"scheduler_metric\",\n",
    "    log_x=True,\n",
    "    width=1_000,\n",
    "    title=\"Allocated tasks depending on the scheduling step size<br><sup>Online mixed curves, 60 blocks, no initial blocks, 100 tasks per block on average, lifetime = 20 blocks, N = 10_000 (i.e. almost continuous unlocking)</sup>\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8eab72c90ef7b6cf7a47cf9058599fe69878ae5c291bf7d8c10fb9498bc1b89e"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
